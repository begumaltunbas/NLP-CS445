{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 609
        },
        "id": "JWvnWFHt_TqY",
        "outputId": "3065a18f-e465-4bd0-cb91-8a7131e23002"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting scikit-learn<0.24\n",
            "  Downloading scikit_learn-0.23.2-cp37-cp37m-manylinux1_x86_64.whl (6.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.8 MB 4.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from scikit-learn<0.24) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scikit-learn<0.24) (1.21.6)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn<0.24) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn<0.24) (3.1.0)\n",
            "Installing collected packages: scikit-learn\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.0.2\n",
            "    Uninstalling scikit-learn-1.0.2:\n",
            "      Successfully uninstalled scikit-learn-1.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "yellowbrick 1.4 requires scikit-learn>=1.0.0, but you have scikit-learn 0.23.2 which is incompatible.\n",
            "imbalanced-learn 0.8.1 requires scikit-learn>=0.24, but you have scikit-learn 0.23.2 which is incompatible.\u001b[0m\n",
            "Successfully installed scikit-learn-0.23.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "sklearn"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sklearn-crfsuite\n",
            "  Downloading sklearn_crfsuite-0.3.6-py2.py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from sklearn-crfsuite) (0.8.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sklearn-crfsuite) (1.15.0)\n",
            "Collecting python-crfsuite>=0.8.3\n",
            "  Downloading python_crfsuite-0.9.8-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (965 kB)\n",
            "\u001b[K     |████████████████████████████████| 965 kB 4.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.7/dist-packages (from sklearn-crfsuite) (4.64.0)\n",
            "Installing collected packages: python-crfsuite, sklearn-crfsuite\n",
            "Successfully installed python-crfsuite-0.9.8 sklearn-crfsuite-0.3.6\n"
          ]
        }
      ],
      "source": [
        "!pip install -U 'scikit-learn<0.24'\n",
        "!pip install sklearn-crfsuite\n",
        "\n",
        "# YOU NEED TO RESTART THE RUNTIME!!!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fZteNYk03GPL",
        "outputId": "f8a0bbe0-6689-4bd3-afca-42da6737c1f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Run this cell to mount your drive to this notebook in order to read the datasets\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Du79PuQ7-MD8"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yOuZQf_I-PIq"
      },
      "source": [
        "## Read Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "YF7EABYQ-JNt"
      },
      "outputs": [],
      "source": [
        "# Put the folder path where the datasets are located\n",
        "PATH = \"/content/drive/MyDrive/445/dataset\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "fmYh526h-QC1"
      },
      "outputs": [],
      "source": [
        "# function to read data, return list of tuples each tuple represents a token contains word, pos tag, chunk tag, and ner tag\n",
        "# Loading the libraries\n",
        "\n",
        "def read_data(filename) -> list:\n",
        "  file1 = open('/content/drive/MyDrive/445/dataset/'+filename, 'r')\n",
        "  count = 0\n",
        "  all_tuples=[]\n",
        "  big_tuples=[]\n",
        "  for line in file1:\n",
        "      count += 1\n",
        "      words=line.split()\n",
        "      if len(words) !=0:\n",
        "        word=words[0]\n",
        "        pos_tag=words[1]\n",
        "        chunk_tag=words[2]\n",
        "        ner_tag=words[3]\n",
        "        ###ignore docstart add here\n",
        "        if word!='-DOCSTART-':\n",
        "          my_tuple = (word, pos_tag, chunk_tag,ner_tag)\n",
        "          all_tuples.append(my_tuple)\n",
        "        else:\n",
        "            next(file1,None) # consume next line\n",
        "            continue # skip this line\n",
        "      else:\n",
        "        #print(\"neden\", word)\n",
        "        big_tuples.append(all_tuples)\n",
        "        all_tuples=[]\n",
        "\n",
        "    \n",
        "  #print(words)\n",
        "  file1.close()  \n",
        "  return big_tuples\n",
        "  ### add sentence wise \n",
        "\n",
        "####SOURCE: https://www.geeksforgeeks.org/read-a-file-line-by-line-in-python/\n",
        "## https://stackoverflow.com/questions/2592798/how-can-i-skip-the-current-item-and-the-next-in-a-python-loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "pgPCBhbj-dSJ"
      },
      "outputs": [],
      "source": [
        "# read data with your custom function\n",
        "train_data = read_data(\"train.txt\")\n",
        "val_data = read_data(\"valid.txt\")\n",
        "test_data = read_data(\"test.txt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oTBHJeDm1RZr",
        "outputId": "3778cafc-c68c-4aed-b3a2-d146ef41674f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14041\n",
            "3250\n",
            "3453\n"
          ]
        }
      ],
      "source": [
        "print(len(train_data))\n",
        "print(len(val_data))\n",
        "print(len(test_data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "M7yU5p8wuGo7",
        "outputId": "cd12a561-a57f-4a29-8dd6-07a2e8167b1f"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nnew_train=[]\\nfor i in range(len(train_data)):\\n  if train_data[i]!=[]:\\n    new_train.append(train_data[i])\\n\\nnew_val=[]\\nfor i in range(len(val_data)):\\n  if val_data[i]!=[]:\\n    new_val.append(val_data[i])\\n\\nnew_test=[]\\nfor i in range(len(test_data)):\\n  if test_data[i]!=[]:\\n    new_test.append(test_data[i])\\n\\n\\ntrain_data=new_train\\nval_data=new_val\\ntest_data=new_test\\n'"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''\n",
        "new_train=[]\n",
        "for i in range(len(train_data)):\n",
        "  if train_data[i]!=[]:\n",
        "    new_train.append(train_data[i])\n",
        "\n",
        "new_val=[]\n",
        "for i in range(len(val_data)):\n",
        "  if val_data[i]!=[]:\n",
        "    new_val.append(val_data[i])\n",
        "\n",
        "new_test=[]\n",
        "for i in range(len(test_data)):\n",
        "  if test_data[i]!=[]:\n",
        "    new_test.append(test_data[i])\n",
        "\n",
        "\n",
        "train_data=new_train\n",
        "val_data=new_val\n",
        "test_data=new_test\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BJF2ZtKB2okl",
        "outputId": "510e8024-f515-462b-8ef1-f12fe4612893"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14041\n",
            "3250\n",
            "3453\n"
          ]
        }
      ],
      "source": [
        "print(len(train_data))\n",
        "print(len(val_data))\n",
        "print(len(test_data))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ECYsXDBl-7mx"
      },
      "source": [
        "# Create Gazetteer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_dft8eaL4Fe_",
        "outputId": "e58d63fe-b9f5-45be-d712-272ac97312f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1VmIrQyBeIHmpSxhvMjsaRU5z3stW3pqS/wikipedia_pages\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/445/wikipedia_pages/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FV6x8_-C4Mbm"
      },
      "outputs": [],
      "source": [
        "os.chdir(\"/content/drive/MyDrive/445/wikipedia_pages/\")\n",
        "listt=os.listdir()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "lNiniCdU7GEy",
        "outputId": "ac6c96d4-b132-479b-e429-259383993291"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\ntext=json_dictionary[\"text\"]\\nstart=text.find(\\'\"&gt;\\')\\nend=text.find(\\';/a&gt\\')\\ntext[start+5:end-3]\\n'"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''\n",
        "text=json_dictionary[\"text\"]\n",
        "start=text.find('\"&gt;')\n",
        "end=text.find(';/a&gt')\n",
        "text[start+5:end-3]\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hMH0NR334XGr"
      },
      "outputs": [],
      "source": [
        "\n",
        "# load wikipedia pages\n",
        "gazetteer=[]\n",
        "for i in range(len(listt)):\n",
        "  path=\"/content/drive/MyDrive/445/wikipedia_pages/\"+listt[i]\n",
        "  myfile = open(path)\n",
        "  json_dictionary = json.load(myfile)\n",
        "  #print(json_dictionary)\n",
        "  text=json_dictionary[\"text\"]\n",
        "  title=json_dictionary[\"title\"]\n",
        "  #start=text.find('\"&gt;')\n",
        "  #end=text.find('/a&gt')\n",
        "  regex = '\"&gt;([^&]*)'\n",
        "  matches=re.findall(regex,text)\n",
        "  if title not in gazetteer:\n",
        "    gazetteer.append(title)\n",
        "  #print(matches[2])\n",
        "  for i in matches:\n",
        "    if i not in gazetteer:\n",
        "      gazetteer.append(i)\n",
        "    else:\n",
        "      continue\n",
        "    \n",
        "  \n",
        "\n",
        "  myfile.close()\n",
        "\n",
        "#https://www.w3schools.com/python/python_regex.asp\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jq83TB1RiE9-"
      },
      "outputs": [],
      "source": [
        "#gazetteer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "SK6R3SzM-_6g",
        "outputId": "3a705e58-442c-4a95-9b46-747b424e8c80"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nimport json\\nfile = open(\"/content/drive/MyDrive/445/wikipedia_pages/25.json\")\\njson_dictionary = json.load(file)\\nfile.close()\\njson_dictionary\\n\\n####hrefleri sırayla alarak listeye at unique sekilde \\n'"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# load wikipedia pages\n",
        "\n",
        "'''\n",
        "import json\n",
        "file = open(\"/content/drive/MyDrive/445/wikipedia_pages/25.json\")\n",
        "json_dictionary = json.load(file)\n",
        "file.close()\n",
        "json_dictionary\n",
        "\n",
        "####hrefleri sırayla alarak listeye at unique sekilde \n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IPBcE1TuQu2D"
      },
      "outputs": [],
      "source": [
        "# you can also define rules to improve your gazetteer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JXeoJckq_BK5",
        "outputId": "a3124bb6-c4d0-4cfd-e4aa-ae995420d908"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "379408"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# print the size of your gazetteer\n",
        "len(gazetteer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8hbhw-VC_Bni"
      },
      "source": [
        "# Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "INZH7AlE_Fnw"
      },
      "source": [
        "## Conditional Random Fields (CRF)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "07ac67uI_Ity"
      },
      "source": [
        "### Extract features for CRF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UKh8kvu6_Dze",
        "outputId": "d2604e04-244b-4e63-fe72-c3c8cdb98fe7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "import sklearn_crfsuite\n",
        "from sklearn.metrics import make_scorer\n",
        "from sklearn_crfsuite import scorers\n",
        "from sklearn_crfsuite import metrics\n",
        "from sklearn.model_selection import GridSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4Sk7ek6Sf7S",
        "outputId": "a675c912-7f65-469e-8b4d-f93b8ac60cd5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "word='HEY -  3'\n",
        "True if '-' in word and word.isupper() and any(char.isdigit() for char in word)  else False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z3e-22yCGdgc"
      },
      "outputs": [],
      "source": [
        "def wordshape(text):\n",
        "  import re\n",
        "  t1 = re.sub('[A-Z]', 'X',text)\n",
        "  t2 = re.sub('[a-z]', 'x', t1)\n",
        "  return re.sub('[0-9]', 'd', t2)\n",
        "\n",
        "def short_word_shape(word_shape_text):\n",
        "  string=word_shape_text[0]\n",
        "  for i in range(1,len(word_shape_text)):\n",
        "    if word_shape_text[i]!=string[-1]:\n",
        "      string=string+word_shape_text[i]\n",
        "\n",
        "  return string"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5fl0gZzJGQes"
      },
      "outputs": [],
      "source": [
        "text=\"O'xoFnll9\"\n",
        "a=wordshape(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "-tZpTMStGg-O",
        "outputId": "1914e5e7-454b-42ed-ab74-692afcdb8040"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"X'xXxd\""
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "short_word_shape(a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "Q2kY95FOKcLz",
        "outputId": "d0d4b950-2193-4bc7-8735-c097a486fe19"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"X'xxXxxxd\""
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y_8lrN7Z_bHz"
      },
      "outputs": [],
      "source": [
        "# create a function to extract features for each token\n",
        "ps = PorterStemmer()\n",
        "stop_list=stopwords.words(\"english\")\n",
        "\n",
        "\n",
        "\n",
        "def token2features(sentence: list, idx: int) -> dict:\n",
        "    word = sentence[idx][0]\n",
        "    postag = sentence[idx][1]\n",
        "    chunktag = sentence[idx][2]\n",
        "    neighbors=[]\n",
        "    #nertag = sentence[i][3] this is y label \n",
        "    w_shape=wordshape(word)\n",
        "    short_w_shape=short_word_shape(w_shape)\n",
        "    stem= ps.stem(word)\n",
        "    features = {\n",
        "        'stem': stem,\n",
        "        'pos_tag':postag,\n",
        "        'chunk_tag':chunktag,\n",
        "        'SOS': False, \n",
        "        'EOS':False, \n",
        "        'start_capital': word[0].isupper(),\n",
        "        'w_shape':w_shape ,\n",
        "        'w_short_shape':short_w_shape,\n",
        "        'contain_num':  any(char.isdigit() for char in word),\n",
        "        'contain_hyphen': True if '-' in word else False,\n",
        "        'upper_digit_dash':True if '-' in word and word.isupper() and any(char.isdigit() for char in word)  else False, ### burada ilk letter mı hepsi mi upper\n",
        "        'contain_prefix': word[:4],\n",
        "        'contain_suffix':word[-4:], \n",
        "        'uppercase':word.isupper(),\n",
        "        'is_stopword': True  if word in stop_list else False,\n",
        "        'neighboring words': [], ##first empty?\n",
        "        'short_shape_neighbor':\"\",\n",
        "        'shape_neighbor':\"\", \n",
        "        'is_gazetteer': True  if word in gazetteer else False,\n",
        "       }\n",
        "\n",
        "    if idx > 0:  #previous neighbor\n",
        "      word_prev = sentence[idx-1][0] \n",
        "      postag_prev = sentence[idx-1][1]\n",
        "      chunktag_prev = sentence[idx-1][2]\n",
        "      word_shape=wordshape(word_prev)\n",
        "      short_w_shape=short_word_shape(word_shape)\n",
        "      neighbors.append(word_prev)\n",
        "      features.update({\n",
        "          'neighboring words': neighbors,\n",
        "          'short_shape_neighbor':short_w_shape, \n",
        "          'shape_neighbor':word_shape,  \n",
        "      })\n",
        "    else:\n",
        "      features['SOS'] = True\n",
        "\n",
        "    if idx < len(sentence)-1: ###next neighbor \n",
        "      word_next = sentence[idx+1][0]\n",
        "      postag_next = sentence[idx+1][1]\n",
        "      chunktag_next = sentence[idx+1][2]\n",
        "      word_shape=wordshape(word_next)\n",
        "      short_w_shape=short_word_shape(word_shape)\n",
        "      neighbors.append(word_next)\n",
        "      features.update({\n",
        "          'neighboring words': neighbors,\n",
        "          'short_shape_neighbor':short_w_shape, \n",
        "          'shape_neighbor':word_shape,  \n",
        "      })\n",
        "    else:\n",
        "        features['EOS'] = True\n",
        "    return features\n",
        "\n",
        "####SOURCE : https://eli5.readthedocs.io/en/latest/tutorials/sklearn_crfsuite.html\n",
        "#### https://stackoverflow.com/questions/19859282/check-if-a-string-contains-a-number\n",
        "##https://stackoverflow.com/questions/49945812/is-there-any-word-shape-feature-library-for-ner-in-python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v57POpXU_bK8"
      },
      "outputs": [],
      "source": [
        "# define function to process each token given a sentence\n",
        "def sent2features(sentence: list) -> list:\n",
        "  return [token2features(sentence, i) for i in range(len(sentence))]\n",
        "\n",
        "# get named entity labels from the sentence\n",
        "def sent2labels(sentence: list) -> list:\n",
        "  return [label for token, postag, chunktag ,label in sentence]\n",
        "\n",
        "####SOURCE : https://eli5.readthedocs.io/en/latest/tutorials/sklearn_crfsuite.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ta1NN3b_vkl"
      },
      "outputs": [],
      "source": [
        "# prepare inputs and labels\n",
        "\n",
        "train_sents = [sent2features(s) for s in train_data]\n",
        "val_sents = [sent2features(s) for s in val_data]\n",
        "test_sents = [sent2features(s) for s in test_data]\n",
        "\n",
        "train_labels = [sent2labels(s) for s in train_data]\n",
        "val_labels = [sent2labels(s) for s in val_data]\n",
        "test_labels = [sent2labels(s) for s in test_data]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pb-5WmGq_ERY",
        "outputId": "e177777c-02fd-4a1a-8e10-4b676af021c1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "14041"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(train_sents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "65dcqHOMPsrT",
        "outputId": "a776fda0-c775-4c56-ce0e-33fd5d3622e3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'EOS': False,\n",
              " 'SOS': True,\n",
              " 'chunk_tag': 'B-NP',\n",
              " 'contain_hyphen': False,\n",
              " 'contain_num': False,\n",
              " 'contain_prefix': 'Pete',\n",
              " 'contain_suffix': 'eter',\n",
              " 'is_gazetteer': True,\n",
              " 'is_stopword': False,\n",
              " 'neighboring words': ['Blackburn'],\n",
              " 'pos_tag': 'NNP',\n",
              " 'shape_neighbor': 'Xxxxxxxxx',\n",
              " 'short_shape_neighbor': 'Xx',\n",
              " 'start_capital': True,\n",
              " 'stem': 'peter',\n",
              " 'upper_digit_dash': False,\n",
              " 'uppercase': False,\n",
              " 'w_shape': 'Xxxxx',\n",
              " 'w_short_shape': 'Xx'}"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_sents[1][0] ###num of features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m_XPjjvLAWHV",
        "outputId": "ccdefde9-25da-4e1b-fb75-3cfb750cb3ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best parameters for crf {'algorithm': 'lbfgs', 'all_possible_transitions': True, 'max_iterations': 100}\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "import sklearn_crfsuite\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Set the hyperparameter space that will be scanned.\n",
        "params = {'algorithm':['l2sgd','lbfgs'] , 'all_possible_transitions':[True,False],'max_iterations':[20,100]}\n",
        "\n",
        "# initialize GridSearchCV for CRF\n",
        "\n",
        "crf = sklearn_crfsuite.CRF()\n",
        "\n",
        "crf_grid_search = GridSearchCV(crf, param_grid=params, cv=5)\n",
        "\n",
        "\n",
        "# fitting the model for grid search \n",
        "crf_grid_search.fit(train_sents , train_labels, X_dev=val_sents, y_dev=val_labels)\n",
        "\n",
        "# print best parameter after tuning \n",
        "\n",
        "print(\"Best parameters for crf\",crf_grid_search.best_params_)\n",
        "\n",
        "### https://sklearn-crfsuite.readthedocs.io/en/latest/tutorial.html#hyperparameter-optimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PD6ghswQxzZd"
      },
      "outputs": [],
      "source": [
        "# initialize and train a crf model with best hyper-parameters\n",
        "crf = sklearn_crfsuite.CRF(\n",
        "    algorithm='lbfgs',\n",
        "    max_iterations=100,\n",
        "    all_possible_transitions=True,\n",
        ")\n",
        "crf.fit(train_sents, train_labels,X_dev=val_sents, y_dev=val_labels)\n",
        "labels = list(crf.classes_)\n",
        "labels.remove('O')\n",
        "\n",
        "y_pred = crf.predict(test_sents)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KgfYVqnBA1lA",
        "outputId": "36e4547d-6525-492a-cfbc-285f3e22827d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       B-LOC       0.83      0.88      0.86      1668\n",
            "      B-MISC       0.83      0.76      0.79       702\n",
            "       B-ORG       0.81      0.74      0.77      1661\n",
            "       B-PER       0.86      0.85      0.85      1617\n",
            "       I-LOC       0.73      0.75      0.74       257\n",
            "      I-MISC       0.62      0.65      0.64       216\n",
            "       I-ORG       0.72      0.77      0.74       835\n",
            "       I-PER       0.88      0.95      0.92      1156\n",
            "           O       0.99      0.99      0.99     38323\n",
            "\n",
            "    accuracy                           0.96     46435\n",
            "   macro avg       0.81      0.82      0.81     46435\n",
            "weighted avg       0.96      0.96      0.96     46435\n",
            "\n",
            "F1 score:  0.8205838390809748\n"
          ]
        }
      ],
      "source": [
        "# calculate f1-score and classification report for test using sklearn_crfsuite.metrics class\n",
        "\n",
        "######## ADDD THIS\n",
        "f1=metrics.flat_f1_score(test_labels, y_pred,\n",
        "                      average='weighted', labels=labels)\n",
        "report=metrics.flat_classification_report(test_labels, y_pred)\n",
        "print(report)\n",
        "print(\"F1 score: \", f1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-J68TX5rValm"
      },
      "outputs": [],
      "source": [
        "#train_sents[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WCa-8I5f7YMi"
      },
      "outputs": [],
      "source": [
        "keys=[]\n",
        "for i in train_sents[0][1].keys():\n",
        "  keys.append(i)\n",
        "#keys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GLGAhWTeQBeA"
      },
      "outputs": [],
      "source": [
        "# start from the stem of the token and add features one by one and train a new model with each feature that you add\n",
        "\n",
        "text_file = open(\"/content/drive/MyDrive/445/crf_feature_metrics.txt\", \"w\")\n",
        "f1_arr=[]\n",
        "features=[]\n",
        "pre_arr=[]\n",
        "recall_arr=[]\n",
        "preds=[]\n",
        "for k in range(1,20):\n",
        "  new_train=[]\n",
        "  for i in range(len(train_sents)):\n",
        "    new_sent=[]\n",
        "    for j in range(len(train_sents[i])):\n",
        "      res = {key: train_sents[i][j][key] for key in keys[:k]}\n",
        "      new_sent.append(res)\n",
        "\n",
        "    new_train.append(new_sent)\n",
        "\n",
        "  crf = sklearn_crfsuite.CRF(\n",
        "    algorithm='lbfgs',\n",
        "    max_iterations=100,\n",
        "    all_possible_transitions=True)\n",
        "  \n",
        "  crf.fit(new_train, train_labels)\n",
        "  labels = list(crf.classes_)\n",
        "  labels.remove('O')\n",
        "\n",
        "  y_pred = crf.predict(val_sents)\n",
        "  f1=metrics.flat_f1_score(val_labels, y_pred,\n",
        "                        average='weighted', labels=labels)\n",
        "  precision=metrics.flat_precision_score(val_labels, y_pred,\n",
        "                        average='weighted', labels=labels)\n",
        "  recall=metrics.flat_recall_score(val_labels, y_pred,\n",
        "                        average='weighted', labels=labels)\n",
        "  features.append('+' + str(keys[:k][-1]))\n",
        "  pre_arr.append(precision)\n",
        "  recall_arr.append(recall)\n",
        "  f1_arr.append(f1)\n",
        "  preds.append(y_pred)\n",
        "  \n",
        "  # Open a file with access mode 'a'\n",
        "  with open(\"/content/drive/MyDrive/445/crf_feature_metrics.txt\", \"a\") as file_object:\n",
        "      # Append 'hello' at the end of file\n",
        "      file_object.write(str(keys[:k])+' '+'f1: '+str(f1)+' '+'pre: '+ str(precision)+' '+'re: '+str(recall)+'\\n')\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        },
        "id": "zHyj6PzMBzV6",
        "outputId": "bb409b7f-189e-43b0-a821-52de05a6a4e5"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-5900d144-f5e6-46b5-95a4-19a827e1016c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Features</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>+stem</td>\n",
              "      <td>0.621541</td>\n",
              "      <td>0.805082</td>\n",
              "      <td>0.510868</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>+pos_tag</td>\n",
              "      <td>0.759779</td>\n",
              "      <td>0.783793</td>\n",
              "      <td>0.748576</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>+chunk_tag</td>\n",
              "      <td>0.749769</td>\n",
              "      <td>0.777778</td>\n",
              "      <td>0.731838</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>+SOS</td>\n",
              "      <td>0.761789</td>\n",
              "      <td>0.790533</td>\n",
              "      <td>0.743113</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>+EOS</td>\n",
              "      <td>0.765415</td>\n",
              "      <td>0.792304</td>\n",
              "      <td>0.748227</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>+start_capital</td>\n",
              "      <td>0.780486</td>\n",
              "      <td>0.786615</td>\n",
              "      <td>0.781820</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>+w_shape</td>\n",
              "      <td>0.792287</td>\n",
              "      <td>0.796922</td>\n",
              "      <td>0.789957</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>+w_short_shape</td>\n",
              "      <td>0.788833</td>\n",
              "      <td>0.793605</td>\n",
              "      <td>0.786702</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>+contain_num</td>\n",
              "      <td>0.787757</td>\n",
              "      <td>0.794538</td>\n",
              "      <td>0.784378</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>+contain_hyphen</td>\n",
              "      <td>0.782122</td>\n",
              "      <td>0.785836</td>\n",
              "      <td>0.781355</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>+upper_digit_dash</td>\n",
              "      <td>0.790629</td>\n",
              "      <td>0.795782</td>\n",
              "      <td>0.788213</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>+contain_prefix</td>\n",
              "      <td>0.820883</td>\n",
              "      <td>0.829850</td>\n",
              "      <td>0.813786</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>+contain_suffix</td>\n",
              "      <td>0.843302</td>\n",
              "      <td>0.847744</td>\n",
              "      <td>0.840056</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>+uppercase</td>\n",
              "      <td>0.836893</td>\n",
              "      <td>0.841025</td>\n",
              "      <td>0.834360</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>+is_stopword</td>\n",
              "      <td>0.843231</td>\n",
              "      <td>0.847756</td>\n",
              "      <td>0.840056</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>+neighboring words</td>\n",
              "      <td>0.876992</td>\n",
              "      <td>0.890315</td>\n",
              "      <td>0.865163</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>+short_shape_neighbor</td>\n",
              "      <td>0.883961</td>\n",
              "      <td>0.894814</td>\n",
              "      <td>0.874811</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>+shape_neighbor</td>\n",
              "      <td>0.883246</td>\n",
              "      <td>0.892019</td>\n",
              "      <td>0.875741</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>+is_gazetteer</td>\n",
              "      <td>0.883836</td>\n",
              "      <td>0.894445</td>\n",
              "      <td>0.874927</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5900d144-f5e6-46b5-95a4-19a827e1016c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5900d144-f5e6-46b5-95a4-19a827e1016c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5900d144-f5e6-46b5-95a4-19a827e1016c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                 Features        F1  Precision    Recall\n",
              "0                   +stem  0.621541   0.805082  0.510868\n",
              "1                +pos_tag  0.759779   0.783793  0.748576\n",
              "2              +chunk_tag  0.749769   0.777778  0.731838\n",
              "3                    +SOS  0.761789   0.790533  0.743113\n",
              "4                    +EOS  0.765415   0.792304  0.748227\n",
              "5          +start_capital  0.780486   0.786615  0.781820\n",
              "6                +w_shape  0.792287   0.796922  0.789957\n",
              "7          +w_short_shape  0.788833   0.793605  0.786702\n",
              "8            +contain_num  0.787757   0.794538  0.784378\n",
              "9         +contain_hyphen  0.782122   0.785836  0.781355\n",
              "10      +upper_digit_dash  0.790629   0.795782  0.788213\n",
              "11        +contain_prefix  0.820883   0.829850  0.813786\n",
              "12        +contain_suffix  0.843302   0.847744  0.840056\n",
              "13             +uppercase  0.836893   0.841025  0.834360\n",
              "14           +is_stopword  0.843231   0.847756  0.840056\n",
              "15     +neighboring words  0.876992   0.890315  0.865163\n",
              "16  +short_shape_neighbor  0.883961   0.894814  0.874811\n",
              "17        +shape_neighbor  0.883246   0.892019  0.875741\n",
              "18          +is_gazetteer  0.883836   0.894445  0.874927"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# display the result table\n",
        "d = {'Features': features, 'F1': f1_arr, 'Precision':pre_arr, 'Recall':recall_arr}\n",
        "df = pd.DataFrame(data=d)\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TvZ-Qr14BzZh",
        "outputId": "08bf2456-8176-4abf-9aaf-0b012d3883a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       B-LOC       0.83      0.88      0.86      1668\n",
            "      B-MISC       0.83      0.76      0.79       702\n",
            "       B-ORG       0.81      0.74      0.77      1661\n",
            "       B-PER       0.86      0.85      0.85      1617\n",
            "       I-LOC       0.73      0.75      0.74       257\n",
            "      I-MISC       0.62      0.65      0.64       216\n",
            "       I-ORG       0.72      0.77      0.74       835\n",
            "       I-PER       0.88      0.95      0.92      1156\n",
            "           O       0.99      0.99      0.99     38323\n",
            "\n",
            "    accuracy                           0.96     46435\n",
            "   macro avg       0.81      0.82      0.81     46435\n",
            "weighted avg       0.96      0.96      0.96     46435\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# display the classification report for the best model\n",
        "crf.fit(train_sents, train_labels)\n",
        "labels = list(crf.classes_)\n",
        "labels.remove('O')\n",
        "y_pred = crf.predict(test_sents)\n",
        "print(metrics.flat_classification_report(test_labels, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K4DNBgU6B4Qs"
      },
      "source": [
        "## Recurrent Neural Network (RNN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "h6b7iz44B6kb"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "from keras.models import Model, Input, Sequential\n",
        "from keras.layers import Dense, Flatten, Embedding, Input, Dropout, LSTM, TimeDistributed, Bidirectional\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "from gensim.models import Word2Vec\n",
        "import gensim.downloader as api"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cfVSNob9Ub_8",
        "outputId": "39a433b1-4278-438a-8d80-2c02716b289d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: seqeval in /usr/local/lib/python3.7/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from seqeval) (1.21.6)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval) (0.23.2)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.4.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.1.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install seqeval\n",
        "from seqeval.metrics import f1_score, precision_score, recall_score, classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "c46yqjBiB6sA"
      },
      "outputs": [],
      "source": [
        "# find unique labels and create dictionary to map each label to a unique integer value\n",
        "\n",
        "label_dict={}\n",
        "for i in train_labels:\n",
        "  #print(i)\n",
        "  for j in i:\n",
        "    if j not in label_dict:\n",
        "      label_dict[j]=0\n",
        "k=0\n",
        "for i in label_dict.keys():\n",
        "\n",
        "  label_dict[i]=k\n",
        "  k=k+1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3azVMBLQt7Sw",
        "outputId": "2517c00a-4e6b-43b2-c0d1-b9366dd0ce19"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'B-LOC': 5,\n",
              " 'B-MISC': 2,\n",
              " 'B-ORG': 0,\n",
              " 'B-PER': 3,\n",
              " 'I-LOC': 8,\n",
              " 'I-MISC': 7,\n",
              " 'I-ORG': 6,\n",
              " 'I-PER': 4,\n",
              " 'O': 1}"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "label_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_w9A77jfOTf",
        "outputId": "991e113d-5042-4787-b9fb-9a1939c383a1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('EU', 'NNP', 'B-NP', 'B-ORG'),\n",
              " ('rejects', 'VBZ', 'B-VP', 'O'),\n",
              " ('German', 'JJ', 'B-NP', 'B-MISC'),\n",
              " ('call', 'NN', 'I-NP', 'O'),\n",
              " ('to', 'TO', 'B-VP', 'O'),\n",
              " ('boycott', 'VB', 'I-VP', 'O'),\n",
              " ('British', 'JJ', 'B-NP', 'B-MISC'),\n",
              " ('lamb', 'NN', 'I-NP', 'O'),\n",
              " ('.', '.', 'O', 'O')]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "train_data[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d9b99-FWjXaS",
        "outputId": "9b200af2-def7-40b2-df93-3ee6e934ad75"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['B-ORG', 'O', 'B-MISC', 'O', 'O', 'O', 'B-MISC', 'O', 'O']"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "train_labels[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "qPy3kQzRe5mx"
      },
      "outputs": [],
      "source": [
        "def sent2tokens(sentence: list) -> list:\n",
        "  return [token for token, postag, chunktag ,label in sentence]\n",
        "\n",
        "def labels2integers(labels: list) -> list:\n",
        "  return [label_dict[label] for label in labels]\n",
        "\n",
        "train_tokens = [sent2tokens(s) for s in train_data]\n",
        "val_tokens = [sent2tokens(s) for s in val_data]\n",
        "test_tokens = [sent2tokens(s) for s in test_data]\n",
        "\n",
        "train_labels_int = [labels2integers(s) for s in train_labels]\n",
        "val_labels_int = [labels2integers(s) for s in val_labels]\n",
        "test_labels_int = [labels2integers(s) for s in test_labels]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55_LNLQPeW0I",
        "outputId": "2f9b69a0-8669-4425-ba8f-5fbf8883e0a6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[0, 1, 2, 1, 1, 1, 2, 1, 1], [3, 4], [5, 1]]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "train_labels_int[:3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FXVzPGzSjw3e",
        "outputId": "99581c7b-af47-436a-94f6-2f2dc987d473"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[3, 4]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "train_labels_int[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "EVMM7jLV8ch7",
        "outputId": "022bda85-4026-4c6d-b6fa-dd3b54bf6c30"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 199.5/199.5MB downloaded\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n['fasttext-wiki-news-subwords-300',\\n 'conceptnet-numberbatch-17-06-300',\\n 'word2vec-ruscorpora-300',\\n 'word2vec-google-news-300',\\n 'glove-wiki-gigaword-50',\\n 'glove-wiki-gigaword-100',\\n 'glove-wiki-gigaword-200',\\n 'glove-wiki-gigaword-300',\\n 'glove-twitter-25',\\n 'glove-twitter-50',\\n 'glove-twitter-100',\\n 'glove-twitter-200',\\n '__testing_word2vec-matrix-synopsis']\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "# Create your own word embeddings from scratch and load a pretrained word embeddings\n",
        "\n",
        "import gensim.downloader as api\n",
        "\n",
        "model_gensim = Word2Vec(sentences=train_tokens,min_count=1,size=50) \n",
        "\n",
        "\n",
        "glove_vectors = api.load('glove-twitter-50')\n",
        "\n",
        "\n",
        "\n",
        "#all pre-trained model options below\n",
        "'''\n",
        "['fasttext-wiki-news-subwords-300',\n",
        " 'conceptnet-numberbatch-17-06-300',\n",
        " 'word2vec-ruscorpora-300',\n",
        " 'word2vec-google-news-300',\n",
        " 'glove-wiki-gigaword-50',\n",
        " 'glove-wiki-gigaword-100',\n",
        " 'glove-wiki-gigaword-200',\n",
        " 'glove-wiki-gigaword-300',\n",
        " 'glove-twitter-25',\n",
        " 'glove-twitter-50',\n",
        " 'glove-twitter-100',\n",
        " 'glove-twitter-200',\n",
        " '__testing_word2vec-matrix-synopsis']\n",
        "'''\n",
        "\n",
        "\n",
        "# You can check https://radimrehurek.com/gensim/models/word2vec.html for training a word embeddings from scratch\n",
        "\n",
        "# You can check https://radimrehurek.com/gensim/auto_examples/howtos/run_downloader_api.html and https://github.com/RaRe-Technologies/gensim-data for loading pretrained word embeddings. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BPMw7vkw8ckn",
        "outputId": "7f128c15-e989-4cca-bb8d-03a182bbaec4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "124\n"
          ]
        }
      ],
      "source": [
        "# preprare your dataset for RNN classifier (you need to add padding to labels as well)\n",
        "# Prepare your dataset for CNN classifier\n",
        "my_tokenizer=tf.keras.preprocessing.text.Tokenizer(\n",
        "    num_words=1000000000000,\n",
        "    filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n",
        "    lower=True,\n",
        "    split=' ',\n",
        "    char_level=False,\n",
        "    oov_token=None,)\n",
        "\n",
        "max_tokens=0\n",
        "for j in test_tokens:\n",
        "  length=len(j)\n",
        "  if length>max_tokens:\n",
        "   max_tokens=length\n",
        "\n",
        "\n",
        "print( max_tokens) #### set for max padding\n",
        "\n",
        "max_pad=max_tokens ### 124\n",
        "my_tokenizer.fit_on_texts(train_tokens)\n",
        "train_tokens2 = my_tokenizer.texts_to_sequences(train_tokens) \n",
        "val_tokens2 = my_tokenizer.texts_to_sequences(val_tokens) \n",
        "test_tokens2 = my_tokenizer.texts_to_sequences(test_tokens) \n",
        "\n",
        "#train_labels = my_tokenizer.texts_to_sequences(train_labels) \n",
        "\n",
        "#####PADDING \n",
        "train_tokens2 = pad_sequences(train_tokens2, padding='post', maxlen=max_pad)\n",
        "train_labels_int = pad_sequences(train_labels_int, padding='post', maxlen=max_pad,value=1)\n",
        "\n",
        "val_tokens2 = pad_sequences(val_tokens2, padding='post', maxlen=max_pad)\n",
        "val_labels_int = pad_sequences(val_labels_int, padding='post', maxlen=max_pad,value=1)\n",
        "\n",
        "\n",
        "test_tokens2 = pad_sequences(test_tokens2, padding='post', maxlen=max_pad)\n",
        "test_labels_int = pad_sequences(test_labels_int, padding='post', maxlen=max_pad,value=1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iKBbibMzf4kg",
        "outputId": "c6025be8-b318-40cb-959b-069474848c67"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "124"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "len(train_labels_int[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hEuxnDpabs9R",
        "outputId": "7afdf494-e346-472d-9ede-ea72338f0529"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2, 3, 4, 5, 6, 7, 8], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "np.unique(val_labels_int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kN57pyTYivUU",
        "outputId": "56d563b6-51f9-4c59-b3f1-76ee09090e56"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  988, 10950,   204, ...,     0,     0,     0],\n",
              "       [  773,  1871,     0, ...,     0,     0,     0],\n",
              "       [  725,   149,     0, ...,     0,     0,     0],\n",
              "       ...,\n",
              "       [ 3093,    20,  2146, ...,     0,     0,     0],\n",
              "       [   88,    84,     0, ...,     0,     0,     0],\n",
              "       [ 4383,    16,  2534, ...,     0,     0,     0]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "train_tokens2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3-FBPFYkkeUS",
        "outputId": "518ffd5a-71fb-4c48-f17a-614a5abe54ec"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 1, 2, ..., 1, 1, 1],\n",
              "       [3, 4, 1, ..., 1, 1, 1],\n",
              "       [5, 1, 1, ..., 1, 1, 1],\n",
              "       ...,\n",
              "       [0, 1, 0, ..., 1, 1, 1],\n",
              "       [1, 1, 1, ..., 1, 1, 1],\n",
              "       [0, 1, 0, ..., 1, 1, 1]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "train_labels_int"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "id": "h1rZ6jb18cpl"
      },
      "outputs": [],
      "source": [
        "# Create Embedding Matrices and Layers\n",
        "\n",
        "from numpy import array,asarray,zeros\n",
        "\n",
        "vocab_size=len(my_tokenizer.word_index)+1\n",
        "\n",
        "pretrained=False\n",
        "\n",
        "def create_embedding_matrix(pretrained, my_tokenizer ):\n",
        "  if pretrained: #####PRE-TRAINED WORD EMBEDDING MATRIX\n",
        "    pretrained=True\n",
        "    embedding_matrix = zeros((vocab_size, 50))\n",
        "    for word, index in my_tokenizer.word_index.items():\n",
        "      try:\n",
        "        embedding_vector = glove_vectors[word]\n",
        "        #print(embedding_vector)\n",
        "        embedding_matrix[index] = embedding_vector\n",
        "        #print(\"okpre\")\n",
        "      except:\n",
        "        continue\n",
        "  else: #####TRAINED FROM SCRATCH WORD EMBEDDING MATRIX\n",
        "    pretrained=False\n",
        "    embedding_matrix = zeros((vocab_size, 50))\n",
        "    for word, index in my_tokenizer.word_index.items():\n",
        "      try:\n",
        "        embedding_vector = model_gensim[word]\n",
        "        #print(embedding_vector)\n",
        "        embedding_matrix[index] = embedding_vector\n",
        "        #print(\"ok\")\n",
        "      except:\n",
        "        continue\n",
        "  return embedding_matrix\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "id": "33JSTKCfkmLo"
      },
      "outputs": [],
      "source": [
        "#if want to use pre-trained embeddings make it True, if want to use trained from scratch embeddings make it False\n",
        "pre_trained_embedding_matrix=create_embedding_matrix(True,my_tokenizer)\n",
        "trained_embedding_matrix=create_embedding_matrix(False,my_tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pZeWpVxsK86K",
        "outputId": "1a1bf0e0-aee2-4c23-d0d8-90f674fb6f3e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['B-ORG', 'O', 'B-MISC', 'B-PER', 'I-PER', 'B-LOC', 'I-ORG', 'I-MISC', 'I-LOC'])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "(label_dict.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B6c1O1l8bzVM",
        "outputId": "0c57d5ca-e117-4975-f57d-d1678c0fd725"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "len(label_dict.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kIahWnYKfrgm",
        "outputId": "1d56a182-1419-4965-b90a-4352133f7051"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(14041, 124)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "train_labels_int.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KsW3ZpHSeEvA",
        "outputId": "8cd680b9-b572-4b24-e81c-a79117e69286"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2, 3, 4, 5, 6, 7, 8], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "np.unique(train_labels_int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Us_32sH3i9rc",
        "outputId": "961e9ca5-0191-41bf-c420-27a65eb44f34"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(14041, 124)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "train_labels_int.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "iPqTFV_hqBgz"
      },
      "outputs": [],
      "source": [
        "#from keras.utils import to_categorical\n",
        "\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "train_labels_int_onehot = [to_categorical(i, num_classes = 9) for i in train_labels_int]\n",
        "val_labels_int_onehot = [to_categorical(i, num_classes = 9) for i in val_labels_int]\n",
        "test_labels_int_onehot = [to_categorical(i, num_classes = 9) for i in test_labels_int]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5HNuWniYrPUH",
        "outputId": "0e00564f-2f41-449e-b786-1d8b1ccea792"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(14041, 124)"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "train_tokens2.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_X7e-dn5qrne",
        "outputId": "76f0d4b3-2983-4181-df55-115e5114f68f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(14041, 124, 9)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "np.array(train_labels_int_onehot).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "6DbhQz268cs8"
      },
      "outputs": [],
      "source": [
        "# Create your models and train them"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "jQakYF1WiTqj"
      },
      "outputs": [],
      "source": [
        "\n",
        "###convert labels back to string \n",
        "def int_to_label(y_pred,test_labels_int_onehot):\n",
        "  temp_pred=y_pred.copy()\n",
        "  temp_label=test_labels_int_onehot.copy()\n",
        "\n",
        "  temp_pred = np.argmax(temp_pred, axis=-1)\n",
        "  temp_label = np.argmax(temp_label, axis=-1)\n",
        "\n",
        "\n",
        "  temp_label2=[]\n",
        "  temp_pred2=[]\n",
        "  ####turns int to labels for predictions and true labels\n",
        "  for i in range(len(temp_label)):\n",
        "    new_arr=[]\n",
        "    for j in range(len(temp_label[i])):\n",
        "      for label, integer in label_dict.items():\n",
        "        if temp_label[i][j] == integer:\n",
        "          #print(label)\n",
        "          new_arr.append(label)\n",
        "    #print(new_arr)\n",
        "    temp_label2.append(new_arr)\n",
        "\n",
        "  for i in range(len(temp_pred)):\n",
        "    new_arr=[]\n",
        "    for j in range(len(temp_pred[i])):\n",
        "      for label, integer in label_dict.items():\n",
        "        if temp_pred[i][j] == integer:\n",
        "          #print(label)\n",
        "          new_arr.append(label)\n",
        "    #print(new_arr)\n",
        "    temp_pred2.append(new_arr)\n",
        "\n",
        "  return temp_pred2,temp_label2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "NVBV-Evrl6pv"
      },
      "outputs": [],
      "source": [
        "def remove_padding(y_pred):\n",
        "  preds=[]\n",
        "  for i in range(len(y_pred)):\n",
        "    preds.append(y_pred[i][:len(test_labels[i])])\n",
        "  return preds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mBx3ITfzuWlv"
      },
      "source": [
        "# **RANDOM EMBEDDING**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "ppxRhJoGvGrq"
      },
      "outputs": [],
      "source": [
        "train_labels_int_onehot=np.array(train_labels_int_onehot)\n",
        "val_labels_int_onehot=np.array(val_labels_int_onehot)\n",
        "test_labels_int_onehot=np.array(test_labels_int_onehot)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SIMPLE RNN"
      ],
      "metadata": {
        "id": "aj3F-TCglfi-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rmpVHI-QlFdx",
        "outputId": "c75d93f0-1dbb-4802-b56b-eb56d6b1a57c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, 124, 124)          2605240   \n",
            "                                                                 \n",
            " simple_rnn_1 (SimpleRNN)    (None, 124, 128)          32384     \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 124, 128)          0         \n",
            "                                                                 \n",
            " time_distributed_2 (TimeDis  (None, 124, 20)          2580      \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            " time_distributed_3 (TimeDis  (None, 124, 9)           189       \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,640,393\n",
            "Trainable params: 2,640,393\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "######################################################## BASE MODEL WITH RANDOM EMBEDDING ########################################################\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "# Add Embedding layer\n",
        "model.add(Embedding(vocab_size, 124, input_length=max_pad))\n",
        "\n",
        "#model.add(tf.keras.layers.Conv1D (128, 5, padding = 'same', activation='relu'))\n",
        "\n",
        "model.add(keras.layers.SimpleRNN(128,return_sequences=True))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(TimeDistributed(Dense(20, activation=\"relu\")))\n",
        "# Add timeDistributed Layer\n",
        "model.add(TimeDistributed(Dense(len(label_dict.keys()), activation=\"softmax\")))\n",
        "\n",
        "# Compile model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "#https://towardsdatascience.com/named-entity-recognition-ner-using-keras-bidirectional-lstm-28cd3f301f54"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dbczkuccl7Rq",
        "outputId": "b4cc32fe-b5bc-4437-a658-41188374e746"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "439/439 [==============================] - 71s 160ms/step - loss: 0.1281 - accuracy: 0.9718 - val_loss: 0.0955 - val_accuracy: 0.9796\n",
            "Epoch 2/5\n",
            "439/439 [==============================] - 61s 140ms/step - loss: 0.0366 - accuracy: 0.9884 - val_loss: 0.1145 - val_accuracy: 0.9832\n",
            "Epoch 3/5\n",
            "439/439 [==============================] - 56s 128ms/step - loss: 0.0181 - accuracy: 0.9950 - val_loss: 0.1248 - val_accuracy: 0.9846\n",
            "Epoch 4/5\n",
            "439/439 [==============================] - 54s 124ms/step - loss: 0.0087 - accuracy: 0.9976 - val_loss: 0.1452 - val_accuracy: 0.9853\n",
            "Epoch 5/5\n",
            "439/439 [==============================] - 56s 127ms/step - loss: 0.0054 - accuracy: 0.9985 - val_loss: 0.1513 - val_accuracy: 0.9853\n",
            "108/108 [==============================] - 1s 11ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         LOC       0.41      0.41      0.41      1668\n",
            "        MISC       0.37      0.35      0.36       702\n",
            "         ORG       0.51      0.40      0.45      1661\n",
            "         PER       0.31      0.19      0.23      1617\n",
            "\n",
            "   micro avg       0.41      0.34      0.37      5648\n",
            "   macro avg       0.40      0.34      0.36      5648\n",
            "weighted avg       0.41      0.34      0.36      5648\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "model.fit(train_tokens2, train_labels_int_onehot, epochs=5, verbose=1,validation_data=(val_tokens2, val_labels_int_onehot))\n",
        "# evaluate the model\n",
        "\n",
        "y_pred = model.predict(test_tokens2, verbose=1)\n",
        "pred,true_labels=int_to_label(y_pred,test_labels_int_onehot)##convert integers back to labels\n",
        "preds=remove_padding(pred)### remove padding \n",
        "\n",
        "from seqeval.metrics import classification_report\n",
        "print(classification_report(test_labels, preds))\n",
        "\n",
        "###https://github.com/Akshayc1/named-entity-recognition/blob/master/NER%20using%20Bidirectional%20LSTM%20-%20CRF%20.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kBn9L_ywuh44",
        "outputId": "eeb89f34-f3fc-41ce-e730-120238568241"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_3 (Embedding)     (None, 124, 124)          2605240   \n",
            "                                                                 \n",
            " simple_rnn_3 (SimpleRNN)    (None, 124, 128)          32384     \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 124, 128)          0         \n",
            "                                                                 \n",
            " time_distributed_6 (TimeDis  (None, 124, 40)          5160      \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            " time_distributed_7 (TimeDis  (None, 124, 9)           369       \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,643,153\n",
            "Trainable params: 2,643,153\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        " ####dense arttırıldı 20->40 ismple rnn 128\n",
        "model = Sequential()\n",
        "\n",
        "# Add Embedding layer\n",
        "model.add(Embedding(vocab_size, 124, input_length=max_pad))\n",
        "\n",
        "\n",
        "model.add(keras.layers.SimpleRNN(128,return_sequences=True))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(TimeDistributed(Dense(40, activation=\"relu\")))\n",
        "# Add timeDistributed Layer\n",
        "model.add(TimeDistributed(Dense(len(label_dict.keys()), activation=\"softmax\")))\n",
        "\n",
        "# Compile model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()\n",
        "#https://towardsdatascience.com/named-entity-recognition-ner-using-keras-bidirectional-lstm-28cd3f301f54"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OFC3RuD5uh0V",
        "outputId": "0b0378ac-a6ad-405c-918c-a596e87f1902"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "439/439 [==============================] - 54s 120ms/step - loss: 0.1083 - accuracy: 0.9769 - val_loss: 0.1023 - val_accuracy: 0.9812\n",
            "Epoch 2/5\n",
            "439/439 [==============================] - 52s 118ms/step - loss: 0.0299 - accuracy: 0.9915 - val_loss: 0.1141 - val_accuracy: 0.9843\n",
            "Epoch 3/5\n",
            "439/439 [==============================] - 52s 119ms/step - loss: 0.0128 - accuracy: 0.9964 - val_loss: 0.1283 - val_accuracy: 0.9847\n",
            "Epoch 4/5\n",
            "439/439 [==============================] - 70s 160ms/step - loss: 0.0070 - accuracy: 0.9980 - val_loss: 0.1433 - val_accuracy: 0.9852\n",
            "Epoch 5/5\n",
            "439/439 [==============================] - 67s 152ms/step - loss: 0.0045 - accuracy: 0.9987 - val_loss: 0.1467 - val_accuracy: 0.9851\n",
            "108/108 [==============================] - 2s 12ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         LOC       0.41      0.40      0.40      1668\n",
            "        MISC       0.36      0.35      0.36       702\n",
            "         ORG       0.48      0.39      0.43      1661\n",
            "         PER       0.32      0.19      0.24      1617\n",
            "\n",
            "   micro avg       0.40      0.33      0.36      5648\n",
            "   macro avg       0.39      0.33      0.36      5648\n",
            "weighted avg       0.40      0.33      0.36      5648\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "model.fit(train_tokens2, train_labels_int_onehot, epochs=5, verbose=1,validation_data=(val_tokens2, val_labels_int_onehot))\n",
        "# evaluate the model\n",
        "\n",
        "y_pred = model.predict(test_tokens2, verbose=1)\n",
        "pred,true_labels=int_to_label(y_pred,test_labels_int_onehot)##convert integers back to labels\n",
        "preds=remove_padding(pred)### remove padding \n",
        "\n",
        "from seqeval.metrics import classification_report\n",
        "print(classification_report(test_labels, preds))\n",
        "\n",
        "###https://github.com/Akshayc1/named-entity-recognition/blob/master/NER%20using%20Bidirectional%20LSTM%20-%20CRF%20.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UAinHp6P6q5C",
        "outputId": "24b3129d-7b1b-4615-c043-37711a03a03c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_4 (Embedding)     (None, 124, 124)          2605240   \n",
            "                                                                 \n",
            " simple_rnn_4 (SimpleRNN)    (None, 124, 256)          97536     \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 124, 256)          0         \n",
            "                                                                 \n",
            " time_distributed_8 (TimeDis  (None, 124, 20)          5140      \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            " time_distributed_9 (TimeDis  (None, 124, 9)           189       \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,708,105\n",
            "Trainable params: 2,708,105\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "####dense 20, simplernn 256 oldu\n",
        "model = Sequential()\n",
        "\n",
        "# Add Embedding layer\n",
        "model.add(Embedding(vocab_size, 124, input_length=max_pad))\n",
        "\n",
        "model.add(keras.layers.SimpleRNN(256,return_sequences=True))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(TimeDistributed(Dense(20, activation=\"relu\")))\n",
        "# Add timeDistributed Layer\n",
        "model.add(TimeDistributed(Dense(len(label_dict.keys()), activation=\"softmax\")))\n",
        "\n",
        "# Compile model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()\n",
        "#https://towardsdatascience.com/named-entity-recognition-ner-using-keras-bidirectional-lstm-28cd3f301f54"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Ls04dPq81j9",
        "outputId": "e1dab7c2-fd4c-4aa9-81de-101758c4b3ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "439/439 [==============================] - 60s 134ms/step - loss: 0.0936 - accuracy: 0.9799 - val_loss: 0.1102 - val_accuracy: 0.9807\n",
            "Epoch 2/5\n",
            "439/439 [==============================] - 79s 180ms/step - loss: 0.0270 - accuracy: 0.9920 - val_loss: 0.1187 - val_accuracy: 0.9845\n",
            "Epoch 3/5\n",
            "439/439 [==============================] - 65s 147ms/step - loss: 0.0114 - accuracy: 0.9968 - val_loss: 0.1392 - val_accuracy: 0.9853\n",
            "Epoch 4/5\n",
            "439/439 [==============================] - 82s 188ms/step - loss: 0.0066 - accuracy: 0.9980 - val_loss: 0.1388 - val_accuracy: 0.9851\n",
            "Epoch 5/5\n",
            "439/439 [==============================] - 65s 149ms/step - loss: 0.0045 - accuracy: 0.9986 - val_loss: 0.1532 - val_accuracy: 0.9850\n",
            "108/108 [==============================] - 1s 12ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         LOC       0.40      0.40      0.40      1668\n",
            "        MISC       0.37      0.38      0.37       702\n",
            "         ORG       0.48      0.39      0.43      1661\n",
            "         PER       0.30      0.17      0.22      1617\n",
            "\n",
            "   micro avg       0.40      0.33      0.36      5648\n",
            "   macro avg       0.39      0.34      0.36      5648\n",
            "weighted avg       0.39      0.33      0.35      5648\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "model.fit(train_tokens2, train_labels_int_onehot, epochs=5, verbose=1,validation_data=(val_tokens2, val_labels_int_onehot))\n",
        "# evaluate the model\n",
        "\n",
        "y_pred = model.predict(test_tokens2, verbose=1)\n",
        "pred,true_labels=int_to_label(y_pred,test_labels_int_onehot)##convert integers back to labels\n",
        "preds=remove_padding(pred)### remove padding \n",
        "\n",
        "from seqeval.metrics import classification_report\n",
        "print(classification_report(test_labels, preds))\n",
        "\n",
        "###https://github.com/Akshayc1/named-entity-recognition/blob/master/NER%20using%20Bidirectional%20LSTM%20-%20CRF%20.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q4BV1NoHIHW5",
        "outputId": "aa286016-ed6f-49d2-beaa-7431f7d5f90b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_5 (Embedding)     (None, 124, 124)          2605240   \n",
            "                                                                 \n",
            " simple_rnn_5 (SimpleRNN)    (None, 124, 256)          97536     \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 124, 256)          0         \n",
            "                                                                 \n",
            " time_distributed_10 (TimeDi  (None, 124, 40)          10280     \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            " time_distributed_11 (TimeDi  (None, 124, 9)           369       \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,713,425\n",
            "Trainable params: 2,713,425\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "##dense arttırıldı 20->40 , simplernn 256 \n",
        "model = Sequential()\n",
        "\n",
        "# Add Embedding layer\n",
        "model.add(Embedding(vocab_size, 124, input_length=max_pad))\n",
        "\n",
        "model.add(keras.layers.SimpleRNN(256,return_sequences=True))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(TimeDistributed(Dense(40, activation=\"relu\")))\n",
        "# Add timeDistributed Layer\n",
        "model.add(TimeDistributed(Dense(len(label_dict.keys()), activation=\"softmax\")))\n",
        "\n",
        "# Compile model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()\n",
        "#https://towardsdatascience.com/named-entity-recognition-ner-using-keras-bidirectional-lstm-28cd3f301f54"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "TkwDn5NLIicR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3cb3e9e-ad9a-4831-cfff-27d83157e547"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "439/439 [==============================] - 57s 129ms/step - loss: 0.1134 - accuracy: 0.9784 - val_loss: 0.1044 - val_accuracy: 0.9791\n",
            "Epoch 2/5\n",
            "439/439 [==============================] - 57s 129ms/step - loss: 0.0320 - accuracy: 0.9901 - val_loss: 0.1235 - val_accuracy: 0.9839\n",
            "Epoch 3/5\n",
            "439/439 [==============================] - 60s 136ms/step - loss: 0.0140 - accuracy: 0.9961 - val_loss: 0.1321 - val_accuracy: 0.9850\n",
            "Epoch 4/5\n",
            "439/439 [==============================] - 87s 197ms/step - loss: 0.0075 - accuracy: 0.9978 - val_loss: 0.1407 - val_accuracy: 0.9852\n",
            "Epoch 5/5\n",
            "439/439 [==============================] - 55s 126ms/step - loss: 0.0046 - accuracy: 0.9986 - val_loss: 0.1490 - val_accuracy: 0.9853\n",
            "108/108 [==============================] - 1s 12ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         LOC       0.41      0.39      0.40      1668\n",
            "        MISC       0.37      0.37      0.37       702\n",
            "         ORG       0.51      0.39      0.44      1661\n",
            "         PER       0.30      0.17      0.22      1617\n",
            "\n",
            "   micro avg       0.41      0.33      0.36      5648\n",
            "   macro avg       0.40      0.33      0.36      5648\n",
            "weighted avg       0.40      0.33      0.36      5648\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "model.fit(train_tokens2, train_labels_int_onehot, epochs=5, verbose=1,validation_data=(val_tokens2, val_labels_int_onehot))\n",
        "# evaluate the model\n",
        "\n",
        "y_pred = model.predict(test_tokens2, verbose=1)\n",
        "pred,true_labels=int_to_label(y_pred,test_labels_int_onehot)##convert integers back to labels\n",
        "preds=remove_padding(pred)### remove padding \n",
        "\n",
        "from seqeval.metrics import classification_report\n",
        "print(classification_report(test_labels, preds))\n",
        "\n",
        "###https://github.com/Akshayc1/named-entity-recognition/blob/master/NER%20using%20Bidirectional%20LSTM%20-%20CRF%20.ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BILSTM"
      ],
      "metadata": {
        "id": "A3VlhgTylZr-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##dense  20, BILSTM 128 \n",
        "model = Sequential()\n",
        "\n",
        "# Add Embedding layer\n",
        "model.add(Embedding(vocab_size, 124, input_length=max_pad))\n",
        "\n",
        "model.add(Bidirectional(LSTM(128,return_sequences=True)))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(TimeDistributed(Dense(20, activation=\"relu\")))\n",
        "# Add timeDistributed Layer\n",
        "model.add(TimeDistributed(Dense(len(label_dict.keys()), activation=\"softmax\")))\n",
        "\n",
        "# Compile model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()\n",
        "#https://towardsdatascience.com/named-entity-recognition-ner-using-keras-bidirectional-lstm-28cd3f301f54"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ONMVX8h3imtD",
        "outputId": "a5faf0a5-9ffb-427e-a39e-60c4ff41e5f7"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_6 (Embedding)     (None, 124, 124)          2605240   \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 124, 256)         259072    \n",
            " l)                                                              \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 124, 256)          0         \n",
            "                                                                 \n",
            " time_distributed_12 (TimeDi  (None, 124, 20)          5140      \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            " time_distributed_13 (TimeDi  (None, 124, 9)           189       \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,869,641\n",
            "Trainable params: 2,869,641\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "pvuk387iKb7f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86f533f4-84eb-49fc-ca0c-129687a3b6f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "439/439 [==============================] - 72s 153ms/step - loss: 0.1056 - accuracy: 0.9802 - val_loss: 0.1045 - val_accuracy: 0.9798\n",
            "Epoch 2/5\n",
            "439/439 [==============================] - 8s 19ms/step - loss: 0.0364 - accuracy: 0.9885 - val_loss: 0.1313 - val_accuracy: 0.9823\n",
            "Epoch 3/5\n",
            "439/439 [==============================] - 8s 19ms/step - loss: 0.0206 - accuracy: 0.9937 - val_loss: 0.1450 - val_accuracy: 0.9844\n",
            "Epoch 4/5\n",
            "439/439 [==============================] - 8s 19ms/step - loss: 0.0116 - accuracy: 0.9966 - val_loss: 0.1474 - val_accuracy: 0.9852\n",
            "Epoch 5/5\n",
            "439/439 [==============================] - 8s 19ms/step - loss: 0.0070 - accuracy: 0.9979 - val_loss: 0.1530 - val_accuracy: 0.9854\n",
            "108/108 [==============================] - 1s 7ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         LOC       0.42      0.41      0.41      1668\n",
            "        MISC       0.42      0.39      0.40       702\n",
            "         ORG       0.53      0.42      0.47      1661\n",
            "         PER       0.31      0.18      0.22      1617\n",
            "\n",
            "   micro avg       0.43      0.34      0.38      5648\n",
            "   macro avg       0.42      0.35      0.38      5648\n",
            "weighted avg       0.42      0.34      0.37      5648\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "model.fit(train_tokens2, train_labels_int_onehot, epochs=5, verbose=1,validation_data=(val_tokens2, val_labels_int_onehot))\n",
        "# evaluate the model\n",
        "\n",
        "y_pred = model.predict(test_tokens2, verbose=1)\n",
        "pred,true_labels=int_to_label(y_pred,test_labels_int_onehot)##convert integers back to labels\n",
        "preds=remove_padding(pred)### remove padding \n",
        "\n",
        "from seqeval.metrics import classification_report\n",
        "print(classification_report(test_labels, preds))\n",
        "\n",
        "###https://github.com/Akshayc1/named-entity-recognition/blob/master/NER%20using%20Bidirectional%20LSTM%20-%20CRF%20.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##dense  20,->40 BILSTM 128 \n",
        "model = Sequential()\n",
        "\n",
        "# Add Embedding layer\n",
        "model.add(Embedding(vocab_size, 124, input_length=max_pad))\n",
        "\n",
        "model.add(Bidirectional(LSTM(128,return_sequences=True)))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(TimeDistributed(Dense(40, activation=\"relu\")))\n",
        "# Add timeDistributed Layer\n",
        "model.add(TimeDistributed(Dense(len(label_dict.keys()), activation=\"softmax\")))\n",
        "\n",
        "# Compile model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()\n",
        "#https://towardsdatascience.com/named-entity-recognition-ner-using-keras-bidirectional-lstm-28cd3f301f54"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ey-95hLtituz",
        "outputId": "db68c74a-9531-4bac-d68d-671d82473a73"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_7 (Embedding)     (None, 124, 124)          2605240   \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirectio  (None, 124, 256)         259072    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 124, 256)          0         \n",
            "                                                                 \n",
            " time_distributed_14 (TimeDi  (None, 124, 40)          10280     \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            " time_distributed_15 (TimeDi  (None, 124, 9)           369       \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,874,961\n",
            "Trainable params: 2,874,961\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model.fit(train_tokens2, train_labels_int_onehot, epochs=5, verbose=1,validation_data=(val_tokens2, val_labels_int_onehot))\n",
        "# evaluate the model\n",
        "\n",
        "y_pred = model.predict(test_tokens2, verbose=1)\n",
        "pred,true_labels=int_to_label(y_pred,test_labels_int_onehot)##convert integers back to labels\n",
        "preds=remove_padding(pred)### remove padding \n",
        "\n",
        "from seqeval.metrics import classification_report\n",
        "print(classification_report(test_labels, preds))\n",
        "\n",
        "###https://github.com/Akshayc1/named-entity-recognition/blob/master/NER%20using%20Bidirectional%20LSTM%20-%20CRF%20.ipynb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EbK_lsyfiyui",
        "outputId": "a26ff800-6844-4cb6-fd07-80f0cbbeadf3"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "439/439 [==============================] - 12s 21ms/step - loss: 0.1136 - accuracy: 0.9781 - val_loss: 0.1060 - val_accuracy: 0.9799\n",
            "Epoch 2/5\n",
            "439/439 [==============================] - 9s 19ms/step - loss: 0.0343 - accuracy: 0.9893 - val_loss: 0.1278 - val_accuracy: 0.9827\n",
            "Epoch 3/5\n",
            "439/439 [==============================] - 8s 19ms/step - loss: 0.0175 - accuracy: 0.9948 - val_loss: 0.1370 - val_accuracy: 0.9848\n",
            "Epoch 4/5\n",
            "439/439 [==============================] - 9s 20ms/step - loss: 0.0094 - accuracy: 0.9972 - val_loss: 0.1378 - val_accuracy: 0.9853\n",
            "Epoch 5/5\n",
            "439/439 [==============================] - 8s 19ms/step - loss: 0.0057 - accuracy: 0.9983 - val_loss: 0.1522 - val_accuracy: 0.9854\n",
            "108/108 [==============================] - 1s 7ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         LOC       0.41      0.42      0.42      1668\n",
            "        MISC       0.44      0.40      0.42       702\n",
            "         ORG       0.54      0.43      0.48      1661\n",
            "         PER       0.30      0.16      0.21      1617\n",
            "\n",
            "   micro avg       0.43      0.35      0.38      5648\n",
            "   macro avg       0.42      0.35      0.38      5648\n",
            "weighted avg       0.42      0.35      0.38      5648\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##dense  20, BILSTM 256 \n",
        "model = Sequential()\n",
        "\n",
        "# Add Embedding layer\n",
        "model.add(Embedding(vocab_size, 124, input_length=max_pad))\n",
        "\n",
        "model.add(Bidirectional(LSTM(256,return_sequences=True)))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(TimeDistributed(Dense(20, activation=\"relu\")))\n",
        "# Add timeDistributed Layer\n",
        "model.add(TimeDistributed(Dense(len(label_dict.keys()), activation=\"softmax\")))\n",
        "\n",
        "# Compile model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()\n",
        "#https://towardsdatascience.com/named-entity-recognition-ner-using-keras-bidirectional-lstm-28cd3f301f54"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lsbebaQVizrP",
        "outputId": "3e35e27a-70fd-491b-a822-4411bd24ca39"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_8 (Embedding)     (None, 124, 124)          2605240   \n",
            "                                                                 \n",
            " bidirectional_2 (Bidirectio  (None, 124, 512)         780288    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dropout_8 (Dropout)         (None, 124, 512)          0         \n",
            "                                                                 \n",
            " time_distributed_16 (TimeDi  (None, 124, 20)          10260     \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            " time_distributed_17 (TimeDi  (None, 124, 9)           189       \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,395,977\n",
            "Trainable params: 3,395,977\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model.fit(train_tokens2, train_labels_int_onehot, epochs=5, verbose=1,validation_data=(val_tokens2, val_labels_int_onehot))\n",
        "# evaluate the model\n",
        "\n",
        "y_pred = model.predict(test_tokens2, verbose=1)\n",
        "pred,true_labels=int_to_label(y_pred,test_labels_int_onehot)##convert integers back to labels\n",
        "preds=remove_padding(pred)### remove padding \n",
        "\n",
        "from seqeval.metrics import classification_report\n",
        "print(classification_report(test_labels, preds))\n",
        "\n",
        "###https://github.com/Akshayc1/named-entity-recognition/blob/master/NER%20using%20Bidirectional%20LSTM%20-%20CRF%20.ipynb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZjdCPD52i3li",
        "outputId": "21724041-1ad5-405b-d255-619ae8f52bd4"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "439/439 [==============================] - 12s 22ms/step - loss: 0.0964 - accuracy: 0.9793 - val_loss: 0.1041 - val_accuracy: 0.9794\n",
            "Epoch 2/5\n",
            "439/439 [==============================] - 9s 20ms/step - loss: 0.0357 - accuracy: 0.9887 - val_loss: 0.1282 - val_accuracy: 0.9826\n",
            "Epoch 3/5\n",
            "439/439 [==============================] - 9s 20ms/step - loss: 0.0177 - accuracy: 0.9948 - val_loss: 0.1318 - val_accuracy: 0.9847\n",
            "Epoch 4/5\n",
            "439/439 [==============================] - 9s 20ms/step - loss: 0.0098 - accuracy: 0.9972 - val_loss: 0.1368 - val_accuracy: 0.9852\n",
            "Epoch 5/5\n",
            "439/439 [==============================] - 9s 20ms/step - loss: 0.0062 - accuracy: 0.9982 - val_loss: 0.1472 - val_accuracy: 0.9855\n",
            "108/108 [==============================] - 1s 8ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         LOC       0.44      0.40      0.42      1668\n",
            "        MISC       0.40      0.39      0.39       702\n",
            "         ORG       0.57      0.46      0.51      1661\n",
            "         PER       0.31      0.17      0.22      1617\n",
            "\n",
            "   micro avg       0.45      0.35      0.39      5648\n",
            "   macro avg       0.43      0.36      0.39      5648\n",
            "weighted avg       0.43      0.35      0.39      5648\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##dense  20, BILSTM 256 \n",
        "model = Sequential()\n",
        "\n",
        "# Add Embedding layer\n",
        "model.add(Embedding(vocab_size, 124, input_length=max_pad))\n",
        "\n",
        "model.add(Bidirectional(LSTM(256,return_sequences=True)))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(TimeDistributed(Dense(40, activation=\"relu\")))\n",
        "# Add timeDistributed Layer\n",
        "model.add(TimeDistributed(Dense(len(label_dict.keys()), activation=\"softmax\")))\n",
        "\n",
        "# Compile model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()\n",
        "#https://towardsdatascience.com/named-entity-recognition-ner-using-keras-bidirectional-lstm-28cd3f301f54"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KAyFHRW8i4LA",
        "outputId": "38fcf9c3-55e2-441d-f326-242f8a62df24"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_9 (Embedding)     (None, 124, 124)          2605240   \n",
            "                                                                 \n",
            " bidirectional_3 (Bidirectio  (None, 124, 512)         780288    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dropout_9 (Dropout)         (None, 124, 512)          0         \n",
            "                                                                 \n",
            " time_distributed_18 (TimeDi  (None, 124, 40)          20520     \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            " time_distributed_19 (TimeDi  (None, 124, 9)           369       \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,406,417\n",
            "Trainable params: 3,406,417\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model.fit(train_tokens2, train_labels_int_onehot, epochs=5, verbose=1,validation_data=(val_tokens2, val_labels_int_onehot))\n",
        "# evaluate the model\n",
        "\n",
        "y_pred = model.predict(test_tokens2, verbose=1)\n",
        "pred,true_labels=int_to_label(y_pred,test_labels_int_onehot)##convert integers back to labels\n",
        "preds=remove_padding(pred)### remove padding \n",
        "\n",
        "from seqeval.metrics import classification_report\n",
        "print(classification_report(test_labels, preds))\n",
        "\n",
        "###https://github.com/Akshayc1/named-entity-recognition/blob/master/NER%20using%20Bidirectional%20LSTM%20-%20CRF%20.ipynb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQdw-ndBi6Uf",
        "outputId": "467c17b4-9a44-494e-9710-48338bfa5aea"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "439/439 [==============================] - 13s 22ms/step - loss: 0.0953 - accuracy: 0.9795 - val_loss: 0.1016 - val_accuracy: 0.9795\n",
            "Epoch 2/5\n",
            "439/439 [==============================] - 9s 20ms/step - loss: 0.0332 - accuracy: 0.9896 - val_loss: 0.1249 - val_accuracy: 0.9832\n",
            "Epoch 3/5\n",
            "439/439 [==============================] - 9s 20ms/step - loss: 0.0157 - accuracy: 0.9953 - val_loss: 0.1298 - val_accuracy: 0.9849\n",
            "Epoch 4/5\n",
            "439/439 [==============================] - 9s 20ms/step - loss: 0.0087 - accuracy: 0.9975 - val_loss: 0.1476 - val_accuracy: 0.9853\n",
            "Epoch 5/5\n",
            "439/439 [==============================] - 9s 20ms/step - loss: 0.0053 - accuracy: 0.9984 - val_loss: 0.1527 - val_accuracy: 0.9856\n",
            "108/108 [==============================] - 2s 10ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         LOC       0.43      0.42      0.42      1668\n",
            "        MISC       0.44      0.40      0.42       702\n",
            "         ORG       0.56      0.44      0.50      1661\n",
            "         PER       0.30      0.17      0.21      1617\n",
            "\n",
            "   micro avg       0.44      0.35      0.39      5648\n",
            "   macro avg       0.43      0.36      0.39      5648\n",
            "weighted avg       0.43      0.35      0.38      5648\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pzO3mTe008zN"
      },
      "source": [
        "# **PRE-TRAINED EMBEDDING**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SIMPLE RNN "
      ],
      "metadata": {
        "id": "0g0d9sQylUlQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "######################################################## BASE MODEL WITH PRE-TRAINED EMBEDDING ########################################################\n",
        "#simp RNN 128 dense 20\n",
        "model = Sequential()\n",
        "\n",
        "# Add Embedding layer\n",
        "model.add(Embedding(vocab_size, 50 ,input_length=max_pad,weights=[pre_trained_embedding_matrix],trainable=True))\n",
        "\n",
        "#model.add(tf.keras.layers.Conv1D (128, 5, padding = 'same', activation='relu'))\n",
        "\n",
        "model.add(keras.layers.SimpleRNN(128,return_sequences=True))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(TimeDistributed(Dense(20, activation=\"relu\")))\n",
        "# Add timeDistributed Layer\n",
        "model.add(TimeDistributed(Dense(len(label_dict.keys()), activation=\"softmax\")))\n",
        "\n",
        "# Compile model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "#https://towardsdatascience.com/named-entity-recognition-ner-using-keras-bidirectional-lstm-28cd3f301f54"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f8GrikBwjpsC",
        "outputId": "f4cab31a-b383-4952-8c9a-204f72992f88"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_11 (Embedding)    (None, 124, 50)           1050500   \n",
            "                                                                 \n",
            " simple_rnn_6 (SimpleRNN)    (None, 124, 128)          22912     \n",
            "                                                                 \n",
            " dropout_10 (Dropout)        (None, 124, 128)          0         \n",
            "                                                                 \n",
            " time_distributed_20 (TimeDi  (None, 124, 20)          2580      \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            " time_distributed_21 (TimeDi  (None, 124, 9)           189       \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,076,181\n",
            "Trainable params: 1,076,181\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "6BnyCVBHuhZK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1be74af7-cfe9-4af8-f7b3-bec00421ff35"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "439/439 [==============================] - 56s 124ms/step - loss: 0.1124 - accuracy: 0.9730 - val_loss: 0.0956 - val_accuracy: 0.9822\n",
            "Epoch 2/5\n",
            "439/439 [==============================] - 51s 116ms/step - loss: 0.0348 - accuracy: 0.9903 - val_loss: 0.1087 - val_accuracy: 0.9839\n",
            "Epoch 3/5\n",
            "439/439 [==============================] - 50s 114ms/step - loss: 0.0239 - accuracy: 0.9932 - val_loss: 0.1160 - val_accuracy: 0.9845\n",
            "Epoch 4/5\n",
            "439/439 [==============================] - 52s 119ms/step - loss: 0.0183 - accuracy: 0.9948 - val_loss: 0.1255 - val_accuracy: 0.9850\n",
            "Epoch 5/5\n",
            "439/439 [==============================] - 50s 114ms/step - loss: 0.0148 - accuracy: 0.9957 - val_loss: 0.1307 - val_accuracy: 0.9851\n",
            "108/108 [==============================] - 1s 11ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         LOC       0.41      0.41      0.41      1668\n",
            "        MISC       0.39      0.36      0.38       702\n",
            "         ORG       0.47      0.40      0.43      1661\n",
            "         PER       0.31      0.18      0.23      1617\n",
            "\n",
            "   micro avg       0.41      0.34      0.37      5648\n",
            "   macro avg       0.40      0.34      0.36      5648\n",
            "weighted avg       0.40      0.34      0.36      5648\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "model.fit(train_tokens2, train_labels_int_onehot, epochs=5, verbose=1,validation_data=(val_tokens2, val_labels_int_onehot))\n",
        "# evaluate the model\n",
        "\n",
        "y_pred = model.predict(test_tokens2, verbose=1)\n",
        "pred,true_labels=int_to_label(y_pred,test_labels_int_onehot)##convert integers back to labels\n",
        "preds=remove_padding(pred)### remove padding \n",
        "\n",
        "from seqeval.metrics import classification_report\n",
        "print(classification_report(test_labels, preds))\n",
        "\n",
        "###https://github.com/Akshayc1/named-entity-recognition/blob/master/NER%20using%20Bidirectional%20LSTM%20-%20CRF%20.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "EtUWUrGCOR0-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "757ea988-e18e-474c-ed1e-faea820aa60b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_12\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_12 (Embedding)    (None, 124, 50)           1050500   \n",
            "                                                                 \n",
            " simple_rnn_7 (SimpleRNN)    (None, 124, 128)          22912     \n",
            "                                                                 \n",
            " dropout_11 (Dropout)        (None, 124, 128)          0         \n",
            "                                                                 \n",
            " time_distributed_22 (TimeDi  (None, 124, 40)          5160      \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            " time_distributed_23 (TimeDi  (None, 124, 9)           369       \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,078,941\n",
            "Trainable params: 1,078,941\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "#simpRNN 128 dense 20->40\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "# Add Embedding layer\n",
        "model.add(Embedding(vocab_size, 50 ,input_length=max_pad,weights=[pre_trained_embedding_matrix],trainable=True))\n",
        "\n",
        "#model.add(tf.keras.layers.Conv1D (128, 5, padding = 'same', activation='relu'))\n",
        "\n",
        "model.add(keras.layers.SimpleRNN(128,return_sequences=True))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(TimeDistributed(Dense(40, activation=\"relu\")))\n",
        "# Add timeDistributed Layer\n",
        "model.add(TimeDistributed(Dense(len(label_dict.keys()), activation=\"softmax\")))\n",
        "\n",
        "# Compile model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "#https://towardsdatascience.com/named-entity-recognition-ner-using-keras-bidirectional-lstm-28cd3f301f54"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "VS4oQL76ORwD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc1799f1-a745-4d6c-e184-78328c9f677b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "439/439 [==============================] - 51s 115ms/step - loss: 0.1001 - accuracy: 0.9761 - val_loss: 0.0936 - val_accuracy: 0.9825\n",
            "Epoch 2/5\n",
            "439/439 [==============================] - 50s 114ms/step - loss: 0.0299 - accuracy: 0.9916 - val_loss: 0.1094 - val_accuracy: 0.9842\n",
            "Epoch 3/5\n",
            "439/439 [==============================] - 78s 179ms/step - loss: 0.0204 - accuracy: 0.9942 - val_loss: 0.1145 - val_accuracy: 0.9846\n",
            "Epoch 4/5\n",
            "439/439 [==============================] - 58s 131ms/step - loss: 0.0157 - accuracy: 0.9954 - val_loss: 0.1208 - val_accuracy: 0.9848\n",
            "Epoch 5/5\n",
            "439/439 [==============================] - 51s 115ms/step - loss: 0.0127 - accuracy: 0.9962 - val_loss: 0.1188 - val_accuracy: 0.9847\n",
            "108/108 [==============================] - 1s 11ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         LOC       0.40      0.40      0.40      1668\n",
            "        MISC       0.35      0.35      0.35       702\n",
            "         ORG       0.45      0.41      0.43      1661\n",
            "         PER       0.31      0.19      0.23      1617\n",
            "\n",
            "   micro avg       0.39      0.34      0.36      5648\n",
            "   macro avg       0.38      0.34      0.35      5648\n",
            "weighted avg       0.38      0.34      0.36      5648\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "model.fit(train_tokens2, train_labels_int_onehot, epochs=5, verbose=1,validation_data=(val_tokens2, val_labels_int_onehot))\n",
        "# evaluate the model\n",
        "\n",
        "y_pred = model.predict(test_tokens2, verbose=1)\n",
        "pred,true_labels=int_to_label(y_pred,test_labels_int_onehot)##convert integers back to labels\n",
        "preds=remove_padding(pred)### remove padding \n",
        "\n",
        "from seqeval.metrics import classification_report\n",
        "print(classification_report(test_labels, preds))\n",
        "\n",
        "###https://github.com/Akshayc1/named-entity-recognition/blob/master/NER%20using%20Bidirectional%20LSTM%20-%20CRF%20.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "ZmBGLRALNu9V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3bcc84dc-fe81-4c13-8816-85e05f68a6f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_14\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_14 (Embedding)    (None, 124, 50)           1050500   \n",
            "                                                                 \n",
            " simple_rnn_8 (SimpleRNN)    (None, 124, 256)          78592     \n",
            "                                                                 \n",
            " dropout_12 (Dropout)        (None, 124, 256)          0         \n",
            "                                                                 \n",
            " time_distributed_24 (TimeDi  (None, 124, 20)          5140      \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            " time_distributed_25 (TimeDi  (None, 124, 9)           189       \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,134,421\n",
            "Trainable params: 1,134,421\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "#simpRNN 256 dense 20\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "# Add Embedding layer\n",
        "model.add(Embedding(vocab_size, 50 ,input_length=max_pad,weights=[pre_trained_embedding_matrix],trainable=True))\n",
        "\n",
        "#model.add(tf.keras.layers.Conv1D (128, 5, padding = 'same', activation='relu'))\n",
        "\n",
        "model.add(keras.layers.SimpleRNN(256,return_sequences=True))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(TimeDistributed(Dense(20, activation=\"relu\")))\n",
        "# Add timeDistributed Layer\n",
        "model.add(TimeDistributed(Dense(len(label_dict.keys()), activation=\"softmax\")))\n",
        "\n",
        "# Compile model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "#https://towardsdatascience.com/named-entity-recognition-ner-using-keras-bidirectional-lstm-28cd3f301f54"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "model.fit(train_tokens2, train_labels_int_onehot, epochs=5, verbose=1,validation_data=(val_tokens2, val_labels_int_onehot))\n",
        "# evaluate the model\n",
        "\n",
        "y_pred = model.predict(test_tokens2, verbose=1)\n",
        "pred,true_labels=int_to_label(y_pred,test_labels_int_onehot)##convert integers back to labels\n",
        "preds=remove_padding(pred)### remove padding \n",
        "\n",
        "from seqeval.metrics import classification_report\n",
        "print(classification_report(test_labels, preds))\n",
        "\n",
        "###https://github.com/Akshayc1/named-entity-recognition/blob/master/NER%20using%20Bidirectional%20LSTM%20-%20CRF%20.ipynb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FbYPE_u9j9wT",
        "outputId": "884c18a4-6d21-419c-d802-561ecb532850"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "439/439 [==============================] - 57s 128ms/step - loss: 0.0974 - accuracy: 0.9784 - val_loss: 0.0993 - val_accuracy: 0.9836\n",
            "Epoch 2/5\n",
            "439/439 [==============================] - 58s 133ms/step - loss: 0.0258 - accuracy: 0.9929 - val_loss: 0.1076 - val_accuracy: 0.9844\n",
            "Epoch 3/5\n",
            "439/439 [==============================] - 57s 129ms/step - loss: 0.0182 - accuracy: 0.9948 - val_loss: 0.1133 - val_accuracy: 0.9848\n",
            "Epoch 4/5\n",
            "439/439 [==============================] - 56s 127ms/step - loss: 0.0140 - accuracy: 0.9960 - val_loss: 0.1221 - val_accuracy: 0.9850\n",
            "Epoch 5/5\n",
            "439/439 [==============================] - 55s 126ms/step - loss: 0.0113 - accuracy: 0.9966 - val_loss: 0.1279 - val_accuracy: 0.9851\n",
            "108/108 [==============================] - 1s 12ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         LOC       0.40      0.42      0.41      1668\n",
            "        MISC       0.39      0.38      0.38       702\n",
            "         ORG       0.50      0.38      0.44      1661\n",
            "         PER       0.31      0.19      0.24      1617\n",
            "\n",
            "   micro avg       0.41      0.34      0.37      5648\n",
            "   macro avg       0.40      0.34      0.37      5648\n",
            "weighted avg       0.41      0.34      0.36      5648\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#simpRNN 256 dense 20->40\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "# Add Embedding layer\n",
        "model.add(Embedding(vocab_size, 50 ,input_length=max_pad,weights=[pre_trained_embedding_matrix],trainable=True))\n",
        "\n",
        "#model.add(tf.keras.layers.Conv1D (128, 5, padding = 'same', activation='relu'))\n",
        "\n",
        "model.add(keras.layers.SimpleRNN(256,return_sequences=True))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(TimeDistributed(Dense(40, activation=\"relu\")))\n",
        "# Add timeDistributed Layer\n",
        "model.add(TimeDistributed(Dense(len(label_dict.keys()), activation=\"softmax\")))\n",
        "\n",
        "# Compile model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "#https://towardsdatascience.com/named-entity-recognition-ner-using-keras-bidirectional-lstm-28cd3f301f54"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ARl7w-a0j-4O",
        "outputId": "3eb000e8-c840-4750-9b2f-c2776ae66a14"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_15\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_15 (Embedding)    (None, 124, 50)           1050500   \n",
            "                                                                 \n",
            " simple_rnn_9 (SimpleRNN)    (None, 124, 256)          78592     \n",
            "                                                                 \n",
            " dropout_13 (Dropout)        (None, 124, 256)          0         \n",
            "                                                                 \n",
            " time_distributed_26 (TimeDi  (None, 124, 40)          10280     \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            " time_distributed_27 (TimeDi  (None, 124, 9)           369       \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,139,741\n",
            "Trainable params: 1,139,741\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "model.fit(train_tokens2, train_labels_int_onehot, epochs=5, verbose=1,validation_data=(val_tokens2, val_labels_int_onehot))\n",
        "# evaluate the model\n",
        "\n",
        "y_pred = model.predict(test_tokens2, verbose=1)\n",
        "pred,true_labels=int_to_label(y_pred,test_labels_int_onehot)##convert integers back to labels\n",
        "preds=remove_padding(pred)### remove padding \n",
        "\n",
        "from seqeval.metrics import classification_report\n",
        "print(classification_report(test_labels, preds))\n",
        "\n",
        "###https://github.com/Akshayc1/named-entity-recognition/blob/master/NER%20using%20Bidirectional%20LSTM%20-%20CRF%20.ipynb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wxvVLH68kCCx",
        "outputId": "fe935f8d-f611-4d85-b506-53ed2b8d00d1"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "439/439 [==============================] - 59s 133ms/step - loss: 0.0845 - accuracy: 0.9796 - val_loss: 0.0982 - val_accuracy: 0.9829\n",
            "Epoch 2/5\n",
            "439/439 [==============================] - 55s 126ms/step - loss: 0.0297 - accuracy: 0.9917 - val_loss: 0.1158 - val_accuracy: 0.9842\n",
            "Epoch 3/5\n",
            "439/439 [==============================] - 55s 125ms/step - loss: 0.0209 - accuracy: 0.9939 - val_loss: 0.1219 - val_accuracy: 0.9846\n",
            "Epoch 4/5\n",
            "439/439 [==============================] - 55s 126ms/step - loss: 0.0162 - accuracy: 0.9952 - val_loss: 0.1232 - val_accuracy: 0.9848\n",
            "Epoch 5/5\n",
            "439/439 [==============================] - 54s 124ms/step - loss: 0.0131 - accuracy: 0.9961 - val_loss: 0.1364 - val_accuracy: 0.9851\n",
            "108/108 [==============================] - 1s 12ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         LOC       0.40      0.41      0.40      1668\n",
            "        MISC       0.37      0.36      0.37       702\n",
            "         ORG       0.51      0.40      0.45      1661\n",
            "         PER       0.32      0.18      0.23      1617\n",
            "\n",
            "   micro avg       0.41      0.33      0.37      5648\n",
            "   macro avg       0.40      0.34      0.36      5648\n",
            "weighted avg       0.41      0.33      0.36      5648\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BILSTM "
      ],
      "metadata": {
        "id": "igo3_tillP1a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##dense  20, BILSTM 128 \n",
        "model = Sequential()\n",
        "\n",
        "# Add Embedding layer\n",
        "model.add(Embedding(vocab_size, 50 ,input_length=max_pad,weights=[pre_trained_embedding_matrix],trainable=True))\n",
        "\n",
        "model.add(Bidirectional(LSTM(128,return_sequences=True)))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(TimeDistributed(Dense(20, activation=\"relu\")))\n",
        "# Add timeDistributed Layer\n",
        "model.add(TimeDistributed(Dense(len(label_dict.keys()), activation=\"softmax\")))\n",
        "\n",
        "# Compile model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()\n",
        "#https://towardsdatascience.com/named-entity-recognition-ner-using-keras-bidirectional-lstm-28cd3f301f54"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YlDoB98Dk7PU",
        "outputId": "58233b68-7c57-4948-d438-ab3d224c6ea6"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_16 (Embedding)    (None, 124, 50)           1050500   \n",
            "                                                                 \n",
            " bidirectional_4 (Bidirectio  (None, 124, 256)         183296    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dropout_14 (Dropout)        (None, 124, 256)          0         \n",
            "                                                                 \n",
            " time_distributed_28 (TimeDi  (None, 124, 20)          5140      \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            " time_distributed_29 (TimeDi  (None, 124, 9)           189       \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,239,125\n",
            "Trainable params: 1,239,125\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "model.fit(train_tokens2, train_labels_int_onehot, epochs=5, verbose=1,validation_data=(val_tokens2, val_labels_int_onehot))\n",
        "# evaluate the model\n",
        "\n",
        "y_pred = model.predict(test_tokens2, verbose=1)\n",
        "pred,true_labels=int_to_label(y_pred,test_labels_int_onehot)##convert integers back to labels\n",
        "preds=remove_padding(pred)### remove padding \n",
        "\n",
        "from seqeval.metrics import classification_report\n",
        "print(classification_report(test_labels, preds))\n",
        "\n",
        "###https://github.com/Akshayc1/named-entity-recognition/blob/master/NER%20using%20Bidirectional%20LSTM%20-%20CRF%20.ipynb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SrAuzmVMk_jC",
        "outputId": "4fa3f838-8274-4bbc-b090-514ae6b0d202"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "439/439 [==============================] - 12s 20ms/step - loss: 0.1077 - accuracy: 0.9823 - val_loss: 0.0903 - val_accuracy: 0.9827\n",
            "Epoch 2/5\n",
            "439/439 [==============================] - 8s 19ms/step - loss: 0.0257 - accuracy: 0.9925 - val_loss: 0.1058 - val_accuracy: 0.9844\n",
            "Epoch 3/5\n",
            "439/439 [==============================] - 8s 19ms/step - loss: 0.0164 - accuracy: 0.9951 - val_loss: 0.1146 - val_accuracy: 0.9852\n",
            "Epoch 4/5\n",
            "439/439 [==============================] - 8s 18ms/step - loss: 0.0117 - accuracy: 0.9965 - val_loss: 0.1231 - val_accuracy: 0.9853\n",
            "Epoch 5/5\n",
            "439/439 [==============================] - 8s 19ms/step - loss: 0.0088 - accuracy: 0.9974 - val_loss: 0.1304 - val_accuracy: 0.9856\n",
            "108/108 [==============================] - 1s 7ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         LOC       0.42      0.37      0.39      1668\n",
            "        MISC       0.45      0.38      0.41       702\n",
            "         ORG       0.54      0.48      0.51      1661\n",
            "         PER       0.32      0.18      0.23      1617\n",
            "\n",
            "   micro avg       0.44      0.35      0.39      5648\n",
            "   macro avg       0.43      0.35      0.39      5648\n",
            "weighted avg       0.43      0.35      0.38      5648\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##dense  20->40, BILSTM 128 \n",
        "model = Sequential()\n",
        "\n",
        "# Add Embedding layer\n",
        "model.add(Embedding(vocab_size, 50 ,input_length=max_pad,weights=[pre_trained_embedding_matrix],trainable=True))\n",
        "\n",
        "model.add(Bidirectional(LSTM(128,return_sequences=True)))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(TimeDistributed(Dense(40, activation=\"relu\")))\n",
        "# Add timeDistributed Layer\n",
        "model.add(TimeDistributed(Dense(len(label_dict.keys()), activation=\"softmax\")))\n",
        "\n",
        "# Compile model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()\n",
        "#https://towardsdatascience.com/named-entity-recognition-ner-using-keras-bidirectional-lstm-28cd3f301f54"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DWCYFnPmlAFo",
        "outputId": "b601d298-e6fc-4cd5-cb65-96187fdade03"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_17\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_17 (Embedding)    (None, 124, 50)           1050500   \n",
            "                                                                 \n",
            " bidirectional_5 (Bidirectio  (None, 124, 256)         183296    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dropout_15 (Dropout)        (None, 124, 256)          0         \n",
            "                                                                 \n",
            " time_distributed_30 (TimeDi  (None, 124, 40)          10280     \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            " time_distributed_31 (TimeDi  (None, 124, 9)           369       \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,244,445\n",
            "Trainable params: 1,244,445\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "model.fit(train_tokens2, train_labels_int_onehot, epochs=5, verbose=1,validation_data=(val_tokens2, val_labels_int_onehot))\n",
        "# evaluate the model\n",
        "\n",
        "y_pred = model.predict(test_tokens2, verbose=1)\n",
        "pred,true_labels=int_to_label(y_pred,test_labels_int_onehot)##convert integers back to labels\n",
        "preds=remove_padding(pred)### remove padding \n",
        "\n",
        "from seqeval.metrics import classification_report\n",
        "print(classification_report(test_labels, preds))\n",
        "\n",
        "###https://github.com/Akshayc1/named-entity-recognition/blob/master/NER%20using%20Bidirectional%20LSTM%20-%20CRF%20.ipynb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ylyy2SddlC9b",
        "outputId": "e86faba3-1f0b-4e56-cc11-1b7d14e7212a"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "439/439 [==============================] - 12s 20ms/step - loss: 0.0989 - accuracy: 0.9837 - val_loss: 0.0983 - val_accuracy: 0.9828\n",
            "Epoch 2/5\n",
            "439/439 [==============================] - 8s 19ms/step - loss: 0.0251 - accuracy: 0.9927 - val_loss: 0.1128 - val_accuracy: 0.9846\n",
            "Epoch 3/5\n",
            "439/439 [==============================] - 8s 19ms/step - loss: 0.0153 - accuracy: 0.9955 - val_loss: 0.1220 - val_accuracy: 0.9852\n",
            "Epoch 4/5\n",
            "439/439 [==============================] - 8s 18ms/step - loss: 0.0105 - accuracy: 0.9969 - val_loss: 0.1326 - val_accuracy: 0.9854\n",
            "Epoch 5/5\n",
            "439/439 [==============================] - 8s 19ms/step - loss: 0.0077 - accuracy: 0.9977 - val_loss: 0.1396 - val_accuracy: 0.9857\n",
            "108/108 [==============================] - 1s 7ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         LOC       0.44      0.42      0.43      1668\n",
            "        MISC       0.46      0.42      0.44       702\n",
            "         ORG       0.60      0.45      0.52      1661\n",
            "         PER       0.30      0.18      0.23      1617\n",
            "\n",
            "   micro avg       0.46      0.36      0.40      5648\n",
            "   macro avg       0.45      0.37      0.40      5648\n",
            "weighted avg       0.45      0.36      0.40      5648\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##dense  20-, BILSTM 256 \n",
        "model = Sequential()\n",
        "\n",
        "# Add Embedding layer\n",
        "model.add(Embedding(vocab_size, 50 ,input_length=max_pad,weights=[pre_trained_embedding_matrix],trainable=True))\n",
        "\n",
        "model.add(Bidirectional(LSTM(256,return_sequences=True)))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(TimeDistributed(Dense(20, activation=\"relu\")))\n",
        "# Add timeDistributed Layer\n",
        "model.add(TimeDistributed(Dense(len(label_dict.keys()), activation=\"softmax\")))\n",
        "\n",
        "# Compile model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()\n",
        "#https://towardsdatascience.com/named-entity-recognition-ner-using-keras-bidirectional-lstm-28cd3f301f54"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dyJ3owxAlD5E",
        "outputId": "49c9b521-3392-4f33-c455-1ecec7b4080a"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_18\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_18 (Embedding)    (None, 124, 50)           1050500   \n",
            "                                                                 \n",
            " bidirectional_6 (Bidirectio  (None, 124, 512)         628736    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dropout_16 (Dropout)        (None, 124, 512)          0         \n",
            "                                                                 \n",
            " time_distributed_32 (TimeDi  (None, 124, 20)          10260     \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            " time_distributed_33 (TimeDi  (None, 124, 9)           189       \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,689,685\n",
            "Trainable params: 1,689,685\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "model.fit(train_tokens2, train_labels_int_onehot, epochs=5, verbose=1,validation_data=(val_tokens2, val_labels_int_onehot))\n",
        "# evaluate the model\n",
        "\n",
        "y_pred = model.predict(test_tokens2, verbose=1)\n",
        "pred,true_labels=int_to_label(y_pred,test_labels_int_onehot)##convert integers back to labels\n",
        "preds=remove_padding(pred)### remove padding \n",
        "\n",
        "from seqeval.metrics import classification_report\n",
        "print(classification_report(test_labels, preds))\n",
        "\n",
        "###https://github.com/Akshayc1/named-entity-recognition/blob/master/NER%20using%20Bidirectional%20LSTM%20-%20CRF%20.ipynb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cbobrtvElJwA",
        "outputId": "8463fdb3-1ea4-4e6c-9e61-43ae368364e4"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "439/439 [==============================] - 13s 22ms/step - loss: 0.0814 - accuracy: 0.9844 - val_loss: 0.0930 - val_accuracy: 0.9826\n",
            "Epoch 2/5\n",
            "439/439 [==============================] - 9s 20ms/step - loss: 0.0229 - accuracy: 0.9932 - val_loss: 0.1099 - val_accuracy: 0.9845\n",
            "Epoch 3/5\n",
            "439/439 [==============================] - 9s 20ms/step - loss: 0.0139 - accuracy: 0.9959 - val_loss: 0.1176 - val_accuracy: 0.9852\n",
            "Epoch 4/5\n",
            "439/439 [==============================] - 9s 21ms/step - loss: 0.0096 - accuracy: 0.9972 - val_loss: 0.1226 - val_accuracy: 0.9856\n",
            "Epoch 5/5\n",
            "439/439 [==============================] - 10s 22ms/step - loss: 0.0069 - accuracy: 0.9979 - val_loss: 0.1339 - val_accuracy: 0.9856\n",
            "108/108 [==============================] - 1s 7ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         LOC       0.43      0.41      0.42      1668\n",
            "        MISC       0.47      0.41      0.44       702\n",
            "         ORG       0.59      0.47      0.53      1661\n",
            "         PER       0.30      0.18      0.22      1617\n",
            "\n",
            "   micro avg       0.45      0.36      0.40      5648\n",
            "   macro avg       0.45      0.37      0.40      5648\n",
            "weighted avg       0.44      0.36      0.40      5648\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##dense  20->40, BILSTM 256 \n",
        "model = Sequential()\n",
        "\n",
        "# Add Embedding layer\n",
        "model.add(Embedding(vocab_size, 50 ,input_length=max_pad,weights=[pre_trained_embedding_matrix],trainable=True))\n",
        "\n",
        "model.add(Bidirectional(LSTM(256,return_sequences=True)))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(TimeDistributed(Dense(40, activation=\"relu\")))\n",
        "# Add timeDistributed Layer\n",
        "model.add(TimeDistributed(Dense(len(label_dict.keys()), activation=\"softmax\")))\n",
        "\n",
        "# Compile model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()\n",
        "#https://towardsdatascience.com/named-entity-recognition-ner-using-keras-bidirectional-lstm-28cd3f301f54"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2FPqQxOllKtu",
        "outputId": "ed32623c-39a1-46ae-ea1f-09c2acca93da"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_19\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_19 (Embedding)    (None, 124, 50)           1050500   \n",
            "                                                                 \n",
            " bidirectional_7 (Bidirectio  (None, 124, 512)         628736    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dropout_17 (Dropout)        (None, 124, 512)          0         \n",
            "                                                                 \n",
            " time_distributed_34 (TimeDi  (None, 124, 40)          20520     \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            " time_distributed_35 (TimeDi  (None, 124, 9)           369       \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,700,125\n",
            "Trainable params: 1,700,125\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "model.fit(train_tokens2, train_labels_int_onehot, epochs=5, verbose=1,validation_data=(val_tokens2, val_labels_int_onehot))\n",
        "# evaluate the model\n",
        "\n",
        "y_pred = model.predict(test_tokens2, verbose=1)\n",
        "pred,true_labels=int_to_label(y_pred,test_labels_int_onehot)##convert integers back to labels\n",
        "preds=remove_padding(pred)### remove padding \n",
        "\n",
        "from seqeval.metrics import classification_report\n",
        "print(classification_report(test_labels, preds))\n",
        "\n",
        "###https://github.com/Akshayc1/named-entity-recognition/blob/master/NER%20using%20Bidirectional%20LSTM%20-%20CRF%20.ipynb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ubaOq7xGlM7L",
        "outputId": "f142f3f0-83db-4584-90f5-087b87baec92"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "439/439 [==============================] - 13s 22ms/step - loss: 0.0793 - accuracy: 0.9846 - val_loss: 0.0962 - val_accuracy: 0.9828\n",
            "Epoch 2/5\n",
            "439/439 [==============================] - 9s 20ms/step - loss: 0.0220 - accuracy: 0.9935 - val_loss: 0.1077 - val_accuracy: 0.9845\n",
            "Epoch 3/5\n",
            "439/439 [==============================] - 9s 20ms/step - loss: 0.0137 - accuracy: 0.9959 - val_loss: 0.1169 - val_accuracy: 0.9851\n",
            "Epoch 4/5\n",
            "439/439 [==============================] - 9s 20ms/step - loss: 0.0096 - accuracy: 0.9971 - val_loss: 0.1242 - val_accuracy: 0.9854\n",
            "Epoch 5/5\n",
            "439/439 [==============================] - 9s 20ms/step - loss: 0.0071 - accuracy: 0.9979 - val_loss: 0.1370 - val_accuracy: 0.9857\n",
            "108/108 [==============================] - 1s 7ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         LOC       0.44      0.40      0.42      1668\n",
            "        MISC       0.47      0.41      0.44       702\n",
            "         ORG       0.58      0.47      0.52      1661\n",
            "         PER       0.30      0.18      0.22      1617\n",
            "\n",
            "   micro avg       0.45      0.36      0.40      5648\n",
            "   macro avg       0.45      0.36      0.40      5648\n",
            "weighted avg       0.44      0.36      0.39      5648\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oWdcUzeU1AIp"
      },
      "source": [
        "# **TRAINED EMBEDDING**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SIMPLE RNN"
      ],
      "metadata": {
        "id": "pWcrH20tmGm4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "id": "KRcsWCjt3z5r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d6b7330-11f9-41f3-e2f2-274ea03eedf6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_24\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_24 (Embedding)    (None, 124, 50)           1050500   \n",
            "                                                                 \n",
            " simple_rnn_12 (SimpleRNN)   (None, 124, 128)          22912     \n",
            "                                                                 \n",
            " dropout_20 (Dropout)        (None, 124, 128)          0         \n",
            "                                                                 \n",
            " time_distributed_40 (TimeDi  (None, 124, 20)          2580      \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            " time_distributed_41 (TimeDi  (None, 124, 9)           189       \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,076,181\n",
            "Trainable params: 1,076,181\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "######################################################## BASE MODEL WITH TRAINED EMBEDDING ########################################################\n",
        "#simp RNN 128 dense 20\n",
        "model = Sequential()\n",
        "\n",
        "# Add Embedding layer\n",
        "model.add(Embedding(vocab_size, 50 ,input_length=max_pad,weights=[trained_embedding_matrix],trainable=True))\n",
        "\n",
        "#model.add(tf.keras.layers.Conv1D (128, 5, padding = 'same', activation='relu'))\n",
        "\n",
        "model.add(keras.layers.SimpleRNN(128,return_sequences=True))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(TimeDistributed(Dense(20, activation=\"relu\")))\n",
        "# Add timeDistributed Layer\n",
        "model.add(TimeDistributed(Dense(len(label_dict.keys()), activation=\"softmax\")))\n",
        "\n",
        "# Compile model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "#https://towardsdatascience.com/named-entity-recognition-ner-using-keras-bidirectional-lstm-28cd3f301f54"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "id": "IOpefDNC3z0w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3fef4a3a-6f49-49a7-931d-c87925738768"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "439/439 [==============================] - 74s 165ms/step - loss: 0.1050 - accuracy: 0.9750 - val_loss: 0.1093 - val_accuracy: 0.9804\n",
            "Epoch 2/5\n",
            "439/439 [==============================] - 52s 117ms/step - loss: 0.0395 - accuracy: 0.9884 - val_loss: 0.1201 - val_accuracy: 0.9826\n",
            "Epoch 3/5\n",
            "439/439 [==============================] - 52s 118ms/step - loss: 0.0229 - accuracy: 0.9937 - val_loss: 0.1328 - val_accuracy: 0.9844\n",
            "Epoch 4/5\n",
            "439/439 [==============================] - 52s 118ms/step - loss: 0.0148 - accuracy: 0.9960 - val_loss: 0.1369 - val_accuracy: 0.9846\n",
            "Epoch 5/5\n",
            "439/439 [==============================] - 53s 121ms/step - loss: 0.0110 - accuracy: 0.9969 - val_loss: 0.1432 - val_accuracy: 0.9851\n",
            "108/108 [==============================] - 1s 11ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         LOC       0.40      0.38      0.39      1668\n",
            "        MISC       0.37      0.34      0.36       702\n",
            "         ORG       0.52      0.39      0.45      1661\n",
            "         PER       0.27      0.16      0.20      1617\n",
            "\n",
            "   micro avg       0.40      0.31      0.35      5648\n",
            "   macro avg       0.39      0.32      0.35      5648\n",
            "weighted avg       0.39      0.31      0.35      5648\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "model.fit(train_tokens2, train_labels_int_onehot, epochs=5, verbose=1,validation_data=(val_tokens2, val_labels_int_onehot))\n",
        "# evaluate the model\n",
        "\n",
        "y_pred = model.predict(test_tokens2, verbose=1)\n",
        "pred,true_labels=int_to_label(y_pred,test_labels_int_onehot)##convert integers back to labels\n",
        "preds=remove_padding(pred)### remove padding \n",
        "\n",
        "from seqeval.metrics import classification_report\n",
        "print(classification_report(test_labels, preds))\n",
        "\n",
        "###https://github.com/Akshayc1/named-entity-recognition/blob/master/NER%20using%20Bidirectional%20LSTM%20-%20CRF%20.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "id": "3Sx7afky3zvg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e100a07d-4a13-4ca6-8824-5448a06aca62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_25\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_25 (Embedding)    (None, 124, 50)           1050500   \n",
            "                                                                 \n",
            " simple_rnn_13 (SimpleRNN)   (None, 124, 128)          22912     \n",
            "                                                                 \n",
            " dropout_21 (Dropout)        (None, 124, 128)          0         \n",
            "                                                                 \n",
            " time_distributed_42 (TimeDi  (None, 124, 40)          5160      \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            " time_distributed_43 (TimeDi  (None, 124, 9)           369       \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,078,941\n",
            "Trainable params: 1,078,941\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "\n",
        "#simp RNN 128 dense 20->40\n",
        "model = Sequential()\n",
        "\n",
        "# Add Embedding layer\n",
        "model.add(Embedding(vocab_size, 50 ,input_length=max_pad,weights=[trained_embedding_matrix],trainable=True))\n",
        "\n",
        "#model.add(tf.keras.layers.Conv1D (128, 5, padding = 'same', activation='relu'))\n",
        "\n",
        "model.add(keras.layers.SimpleRNN(128,return_sequences=True))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(TimeDistributed(Dense(40, activation=\"relu\")))\n",
        "# Add timeDistributed Layer\n",
        "model.add(TimeDistributed(Dense(len(label_dict.keys()), activation=\"softmax\")))\n",
        "\n",
        "# Compile model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "#https://towardsdatascience.com/named-entity-recognition-ner-using-keras-bidirectional-lstm-28cd3f301f54"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "id": "-bVgXvip3zqV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13bd418f-bb6f-4288-9504-850325bf0563"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "439/439 [==============================] - 53s 119ms/step - loss: 0.0938 - accuracy: 0.9768 - val_loss: 0.1043 - val_accuracy: 0.9804\n",
            "Epoch 2/5\n",
            "439/439 [==============================] - 52s 119ms/step - loss: 0.0367 - accuracy: 0.9887 - val_loss: 0.1258 - val_accuracy: 0.9824\n",
            "Epoch 3/5\n",
            "439/439 [==============================] - 52s 119ms/step - loss: 0.0218 - accuracy: 0.9937 - val_loss: 0.1311 - val_accuracy: 0.9846\n",
            "Epoch 4/5\n",
            "439/439 [==============================] - 52s 118ms/step - loss: 0.0140 - accuracy: 0.9961 - val_loss: 0.1329 - val_accuracy: 0.9846\n",
            "Epoch 5/5\n",
            "439/439 [==============================] - 54s 123ms/step - loss: 0.0105 - accuracy: 0.9970 - val_loss: 0.1419 - val_accuracy: 0.9852\n",
            "108/108 [==============================] - 1s 11ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         LOC       0.41      0.40      0.41      1668\n",
            "        MISC       0.38      0.35      0.37       702\n",
            "         ORG       0.50      0.38      0.43      1661\n",
            "         PER       0.29      0.17      0.22      1617\n",
            "\n",
            "   micro avg       0.41      0.32      0.36      5648\n",
            "   macro avg       0.40      0.33      0.36      5648\n",
            "weighted avg       0.40      0.32      0.35      5648\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "model.fit(train_tokens2, train_labels_int_onehot, epochs=5, verbose=1,validation_data=(val_tokens2, val_labels_int_onehot))\n",
        "# evaluate the model\n",
        "\n",
        "y_pred = model.predict(test_tokens2, verbose=1)\n",
        "pred,true_labels=int_to_label(y_pred,test_labels_int_onehot)##convert integers back to labels\n",
        "preds=remove_padding(pred)### remove padding \n",
        "\n",
        "from seqeval.metrics import classification_report\n",
        "print(classification_report(test_labels, preds))\n",
        "\n",
        "###https://github.com/Akshayc1/named-entity-recognition/blob/master/NER%20using%20Bidirectional%20LSTM%20-%20CRF%20.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "id": "QJfGBYtWuhTY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e7a73ee-7db5-403b-e8ec-dfee46823a2b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_26\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_26 (Embedding)    (None, 124, 50)           1050500   \n",
            "                                                                 \n",
            " simple_rnn_14 (SimpleRNN)   (None, 124, 256)          78592     \n",
            "                                                                 \n",
            " dropout_22 (Dropout)        (None, 124, 256)          0         \n",
            "                                                                 \n",
            " time_distributed_44 (TimeDi  (None, 124, 20)          5140      \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            " time_distributed_45 (TimeDi  (None, 124, 9)           189       \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,134,421\n",
            "Trainable params: 1,134,421\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "\n",
        "#simp RNN 256 dense 20\n",
        "model = Sequential()\n",
        "\n",
        "# Add Embedding layer\n",
        "model.add(Embedding(vocab_size, 50 ,input_length=max_pad,weights=[trained_embedding_matrix],trainable=True))\n",
        "\n",
        "#model.add(tf.keras.layers.Conv1D (128, 5, padding = 'same', activation='relu'))\n",
        "\n",
        "model.add(keras.layers.SimpleRNN(256,return_sequences=True))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(TimeDistributed(Dense(20, activation=\"relu\")))\n",
        "# Add timeDistributed Layer\n",
        "model.add(TimeDistributed(Dense(len(label_dict.keys()), activation=\"softmax\")))\n",
        "\n",
        "# Compile model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "#https://towardsdatascience.com/named-entity-recognition-ner-using-keras-bidirectional-lstm-28cd3f301f54"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "id": "iyU-zQLx8cx9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3ebab67-d6d1-4dba-f150-b68beb3fbbd7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "439/439 [==============================] - 62s 140ms/step - loss: 0.0970 - accuracy: 0.9761 - val_loss: 0.1132 - val_accuracy: 0.9806\n",
            "Epoch 2/5\n",
            "439/439 [==============================] - 56s 128ms/step - loss: 0.0359 - accuracy: 0.9896 - val_loss: 0.1209 - val_accuracy: 0.9835\n",
            "Epoch 3/5\n",
            "439/439 [==============================] - 56s 129ms/step - loss: 0.0194 - accuracy: 0.9947 - val_loss: 0.1365 - val_accuracy: 0.9848\n",
            "Epoch 4/5\n",
            "439/439 [==============================] - 58s 133ms/step - loss: 0.0123 - accuracy: 0.9965 - val_loss: 0.1370 - val_accuracy: 0.9849\n",
            "Epoch 5/5\n",
            "439/439 [==============================] - 56s 128ms/step - loss: 0.0097 - accuracy: 0.9971 - val_loss: 0.1375 - val_accuracy: 0.9850\n",
            "108/108 [==============================] - 1s 12ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         LOC       0.40      0.41      0.41      1668\n",
            "        MISC       0.37      0.35      0.36       702\n",
            "         ORG       0.49      0.38      0.43      1661\n",
            "         PER       0.29      0.17      0.21      1617\n",
            "\n",
            "   micro avg       0.40      0.33      0.36      5648\n",
            "   macro avg       0.39      0.33      0.35      5648\n",
            "weighted avg       0.39      0.33      0.35      5648\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "model.fit(train_tokens2, train_labels_int_onehot, epochs=5, verbose=1,validation_data=(val_tokens2, val_labels_int_onehot))\n",
        "# evaluate the model\n",
        "\n",
        "y_pred = model.predict(test_tokens2, verbose=1)\n",
        "pred,true_labels=int_to_label(y_pred,test_labels_int_onehot)##convert integers back to labels\n",
        "preds=remove_padding(pred)### remove padding \n",
        "\n",
        "from seqeval.metrics import classification_report\n",
        "print(classification_report(test_labels, preds))\n",
        "\n",
        "###https://github.com/Akshayc1/named-entity-recognition/blob/master/NER%20using%20Bidirectional%20LSTM%20-%20CRF%20.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#simp RNN 256 dense 20->40\n",
        "model = Sequential()\n",
        "\n",
        "# Add Embedding layer\n",
        "model.add(Embedding(vocab_size, 50 ,input_length=max_pad,weights=[trained_embedding_matrix],trainable=True))\n",
        "\n",
        "#model.add(tf.keras.layers.Conv1D (128, 5, padding = 'same', activation='relu'))\n",
        "\n",
        "model.add(keras.layers.SimpleRNN(256,return_sequences=True))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(TimeDistributed(Dense(40, activation=\"relu\")))\n",
        "# Add timeDistributed Layer\n",
        "model.add(TimeDistributed(Dense(len(label_dict.keys()), activation=\"softmax\")))\n",
        "\n",
        "# Compile model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "#https://towardsdatascience.com/named-entity-recognition-ner-using-keras-bidirectional-lstm-28cd3f301f54"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8_67E_-Gkq1x",
        "outputId": "2a73c3fa-5ca8-4402-9cde-7c6bcc05dbc3"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_27\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_27 (Embedding)    (None, 124, 50)           1050500   \n",
            "                                                                 \n",
            " simple_rnn_15 (SimpleRNN)   (None, 124, 256)          78592     \n",
            "                                                                 \n",
            " dropout_23 (Dropout)        (None, 124, 256)          0         \n",
            "                                                                 \n",
            " time_distributed_46 (TimeDi  (None, 124, 40)          10280     \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            " time_distributed_47 (TimeDi  (None, 124, 9)           369       \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,139,741\n",
            "Trainable params: 1,139,741\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "model.fit(train_tokens2, train_labels_int_onehot, epochs=5, verbose=1,validation_data=(val_tokens2, val_labels_int_onehot))\n",
        "# evaluate the model\n",
        "\n",
        "y_pred = model.predict(test_tokens2, verbose=1)\n",
        "pred,true_labels=int_to_label(y_pred,test_labels_int_onehot)##convert integers back to labels\n",
        "preds=remove_padding(pred)### remove padding \n",
        "\n",
        "from seqeval.metrics import classification_report\n",
        "print(classification_report(test_labels, preds))\n",
        "\n",
        "###https://github.com/Akshayc1/named-entity-recognition/blob/master/NER%20using%20Bidirectional%20LSTM%20-%20CRF%20.ipynb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B_UitxYXkuUo",
        "outputId": "ee9fc34f-ac95-41cd-c602-aacb94c69ecb"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "439/439 [==============================] - 57s 129ms/step - loss: 0.0917 - accuracy: 0.9758 - val_loss: 0.1193 - val_accuracy: 0.9810\n",
            "Epoch 2/5\n",
            "439/439 [==============================] - 58s 133ms/step - loss: 0.0357 - accuracy: 0.9892 - val_loss: 0.1208 - val_accuracy: 0.9829\n",
            "Epoch 3/5\n",
            "439/439 [==============================] - 57s 129ms/step - loss: 0.0193 - accuracy: 0.9946 - val_loss: 0.1330 - val_accuracy: 0.9848\n",
            "Epoch 4/5\n",
            "439/439 [==============================] - 56s 129ms/step - loss: 0.0124 - accuracy: 0.9965 - val_loss: 0.1340 - val_accuracy: 0.9849\n",
            "Epoch 5/5\n",
            "439/439 [==============================] - 57s 129ms/step - loss: 0.0096 - accuracy: 0.9972 - val_loss: 0.1409 - val_accuracy: 0.9849\n",
            "108/108 [==============================] - 1s 12ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         LOC       0.41      0.40      0.41      1668\n",
            "        MISC       0.41      0.38      0.39       702\n",
            "         ORG       0.46      0.39      0.42      1661\n",
            "         PER       0.29      0.17      0.21      1617\n",
            "\n",
            "   micro avg       0.40      0.33      0.36      5648\n",
            "   macro avg       0.39      0.33      0.36      5648\n",
            "weighted avg       0.39      0.33      0.35      5648\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BILSTM"
      ],
      "metadata": {
        "id": "5dmR7ZvXmD5d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##dense  20, BILSTM 128 \n",
        "model = Sequential()\n",
        "\n",
        "# Add Embedding layer\n",
        "model.add(Embedding(vocab_size, 50 ,input_length=max_pad,weights=[trained_embedding_matrix],trainable=True))\n",
        "\n",
        "model.add(Bidirectional(LSTM(128,return_sequences=True)))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(TimeDistributed(Dense(20, activation=\"relu\")))\n",
        "# Add timeDistributed Layer\n",
        "model.add(TimeDistributed(Dense(len(label_dict.keys()), activation=\"softmax\")))\n",
        "\n",
        "# Compile model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()\n",
        "#https://towardsdatascience.com/named-entity-recognition-ner-using-keras-bidirectional-lstm-28cd3f301f54"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fyUJJaiNmJ0d",
        "outputId": "980de5b1-ceb3-4e89-ebdc-febf14fb5422"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_28\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_28 (Embedding)    (None, 124, 50)           1050500   \n",
            "                                                                 \n",
            " bidirectional_8 (Bidirectio  (None, 124, 256)         183296    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dropout_24 (Dropout)        (None, 124, 256)          0         \n",
            "                                                                 \n",
            " time_distributed_48 (TimeDi  (None, 124, 20)          5140      \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            " time_distributed_49 (TimeDi  (None, 124, 9)           189       \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,239,125\n",
            "Trainable params: 1,239,125\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "model.fit(train_tokens2, train_labels_int_onehot, epochs=5, verbose=1,validation_data=(val_tokens2, val_labels_int_onehot))\n",
        "# evaluate the model\n",
        "\n",
        "y_pred = model.predict(test_tokens2, verbose=1)\n",
        "pred,true_labels=int_to_label(y_pred,test_labels_int_onehot)##convert integers back to labels\n",
        "preds=remove_padding(pred)### remove padding \n",
        "\n",
        "from seqeval.metrics import classification_report\n",
        "print(classification_report(test_labels, preds))\n",
        "\n",
        "###https://github.com/Akshayc1/named-entity-recognition/blob/master/NER%20using%20Bidirectional%20LSTM%20-%20CRF%20.ipynb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0TExcOVEmJvx",
        "outputId": "753590e5-bb35-4cda-a7aa-361eec9561cc"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "439/439 [==============================] - 12s 21ms/step - loss: 0.1162 - accuracy: 0.9793 - val_loss: 0.1011 - val_accuracy: 0.9809\n",
            "Epoch 2/5\n",
            "439/439 [==============================] - 8s 19ms/step - loss: 0.0378 - accuracy: 0.9887 - val_loss: 0.1206 - val_accuracy: 0.9823\n",
            "Epoch 3/5\n",
            "439/439 [==============================] - 9s 21ms/step - loss: 0.0228 - accuracy: 0.9929 - val_loss: 0.1395 - val_accuracy: 0.9838\n",
            "Epoch 4/5\n",
            "439/439 [==============================] - 8s 18ms/step - loss: 0.0145 - accuracy: 0.9958 - val_loss: 0.1453 - val_accuracy: 0.9850\n",
            "Epoch 5/5\n",
            "439/439 [==============================] - 8s 18ms/step - loss: 0.0098 - accuracy: 0.9973 - val_loss: 0.1492 - val_accuracy: 0.9850\n",
            "108/108 [==============================] - 1s 7ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         LOC       0.41      0.40      0.40      1668\n",
            "        MISC       0.45      0.40      0.42       702\n",
            "         ORG       0.51      0.44      0.47      1661\n",
            "         PER       0.31      0.16      0.21      1617\n",
            "\n",
            "   micro avg       0.43      0.34      0.38      5648\n",
            "   macro avg       0.42      0.35      0.38      5648\n",
            "weighted avg       0.41      0.34      0.37      5648\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##dense  20->40, BILSTM 128 \n",
        "model = Sequential()\n",
        "\n",
        "# Add Embedding layer\n",
        "model.add(Embedding(vocab_size, 50 ,input_length=max_pad,weights=[trained_embedding_matrix],trainable=True))\n",
        "\n",
        "model.add(Bidirectional(LSTM(128,return_sequences=True)))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(TimeDistributed(Dense(40, activation=\"relu\")))\n",
        "# Add timeDistributed Layer\n",
        "model.add(TimeDistributed(Dense(len(label_dict.keys()), activation=\"softmax\")))\n",
        "\n",
        "# Compile model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()\n",
        "#https://towardsdatascience.com/named-entity-recognition-ner-using-keras-bidirectional-lstm-28cd3f301f54"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UL4rpSaymJrV",
        "outputId": "0f09a272-16ba-4925-94c4-37fafaf4221a"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_29\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_29 (Embedding)    (None, 124, 50)           1050500   \n",
            "                                                                 \n",
            " bidirectional_9 (Bidirectio  (None, 124, 256)         183296    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dropout_25 (Dropout)        (None, 124, 256)          0         \n",
            "                                                                 \n",
            " time_distributed_50 (TimeDi  (None, 124, 40)          10280     \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            " time_distributed_51 (TimeDi  (None, 124, 9)           369       \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,244,445\n",
            "Trainable params: 1,244,445\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "model.fit(train_tokens2, train_labels_int_onehot, epochs=5, verbose=1,validation_data=(val_tokens2, val_labels_int_onehot))\n",
        "# evaluate the model\n",
        "\n",
        "y_pred = model.predict(test_tokens2, verbose=1)\n",
        "pred,true_labels=int_to_label(y_pred,test_labels_int_onehot)##convert integers back to labels\n",
        "preds=remove_padding(pred)### remove padding \n",
        "\n",
        "from seqeval.metrics import classification_report\n",
        "print(classification_report(test_labels, preds))\n",
        "\n",
        "###https://github.com/Akshayc1/named-entity-recognition/blob/master/NER%20using%20Bidirectional%20LSTM%20-%20CRF%20.ipynb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U2aphpzGmJmJ",
        "outputId": "5a49b9ff-4759-4456-d13d-e8a29a8c0cc6"
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "439/439 [==============================] - 12s 20ms/step - loss: 0.1022 - accuracy: 0.9812 - val_loss: 0.1047 - val_accuracy: 0.9810\n",
            "Epoch 2/5\n",
            "439/439 [==============================] - 8s 18ms/step - loss: 0.0329 - accuracy: 0.9899 - val_loss: 0.1258 - val_accuracy: 0.9830\n",
            "Epoch 3/5\n",
            "439/439 [==============================] - 8s 19ms/step - loss: 0.0187 - accuracy: 0.9945 - val_loss: 0.1328 - val_accuracy: 0.9845\n",
            "Epoch 4/5\n",
            "439/439 [==============================] - 8s 19ms/step - loss: 0.0112 - accuracy: 0.9968 - val_loss: 0.1396 - val_accuracy: 0.9851\n",
            "Epoch 5/5\n",
            "439/439 [==============================] - 8s 19ms/step - loss: 0.0076 - accuracy: 0.9979 - val_loss: 0.1529 - val_accuracy: 0.9853\n",
            "108/108 [==============================] - 1s 6ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         LOC       0.42      0.41      0.42      1668\n",
            "        MISC       0.47      0.41      0.44       702\n",
            "         ORG       0.59      0.44      0.50      1661\n",
            "         PER       0.29      0.17      0.22      1617\n",
            "\n",
            "   micro avg       0.45      0.35      0.39      5648\n",
            "   macro avg       0.44      0.36      0.39      5648\n",
            "weighted avg       0.44      0.35      0.39      5648\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##dense  20, BILSTM 256 \n",
        "model = Sequential()\n",
        "\n",
        "# Add Embedding layer\n",
        "model.add(Embedding(vocab_size, 50 ,input_length=max_pad,weights=[trained_embedding_matrix],trainable=True))\n",
        "\n",
        "model.add(Bidirectional(LSTM(256,return_sequences=True)))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(TimeDistributed(Dense(20, activation=\"relu\")))\n",
        "# Add timeDistributed Layer\n",
        "model.add(TimeDistributed(Dense(len(label_dict.keys()), activation=\"softmax\")))\n",
        "\n",
        "# Compile model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()\n",
        "#https://towardsdatascience.com/named-entity-recognition-ner-using-keras-bidirectional-lstm-28cd3f301f54"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Vt-Wz3LmTZh",
        "outputId": "157932e7-1fdc-4cf8-9fe3-5b1e2f2eac39"
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_30\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_30 (Embedding)    (None, 124, 50)           1050500   \n",
            "                                                                 \n",
            " bidirectional_10 (Bidirecti  (None, 124, 512)         628736    \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dropout_26 (Dropout)        (None, 124, 512)          0         \n",
            "                                                                 \n",
            " time_distributed_52 (TimeDi  (None, 124, 20)          10260     \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            " time_distributed_53 (TimeDi  (None, 124, 9)           189       \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,689,685\n",
            "Trainable params: 1,689,685\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "model.fit(train_tokens2, train_labels_int_onehot, epochs=5, verbose=1,validation_data=(val_tokens2, val_labels_int_onehot))\n",
        "# evaluate the model\n",
        "\n",
        "y_pred = model.predict(test_tokens2, verbose=1)\n",
        "pred,true_labels=int_to_label(y_pred,test_labels_int_onehot)##convert integers back to labels\n",
        "preds=remove_padding(pred)### remove padding \n",
        "\n",
        "from seqeval.metrics import classification_report\n",
        "print(classification_report(test_labels, preds))\n",
        "\n",
        "###https://github.com/Akshayc1/named-entity-recognition/blob/master/NER%20using%20Bidirectional%20LSTM%20-%20CRF%20.ipynb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6eEBk2mAmTP5",
        "outputId": "c8972b46-dd75-4e58-997f-adc0d743c9ce"
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "439/439 [==============================] - 14s 25ms/step - loss: 0.0842 - accuracy: 0.9831 - val_loss: 0.1146 - val_accuracy: 0.9813\n",
            "Epoch 2/5\n",
            "439/439 [==============================] - 8s 19ms/step - loss: 0.0296 - accuracy: 0.9909 - val_loss: 0.1330 - val_accuracy: 0.9831\n",
            "Epoch 3/5\n",
            "439/439 [==============================] - 9s 20ms/step - loss: 0.0180 - accuracy: 0.9946 - val_loss: 0.1287 - val_accuracy: 0.9843\n",
            "Epoch 4/5\n",
            "439/439 [==============================] - 9s 20ms/step - loss: 0.0117 - accuracy: 0.9967 - val_loss: 0.1367 - val_accuracy: 0.9851\n",
            "Epoch 5/5\n",
            "439/439 [==============================] - 9s 20ms/step - loss: 0.0080 - accuracy: 0.9977 - val_loss: 0.1347 - val_accuracy: 0.9851\n",
            "108/108 [==============================] - 1s 7ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         LOC       0.41      0.42      0.42      1668\n",
            "        MISC       0.40      0.42      0.41       702\n",
            "         ORG       0.55      0.45      0.49      1661\n",
            "         PER       0.32      0.15      0.20      1617\n",
            "\n",
            "   micro avg       0.44      0.35      0.39      5648\n",
            "   macro avg       0.42      0.36      0.38      5648\n",
            "weighted avg       0.43      0.35      0.38      5648\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##dense  20->40, BILSTM 256 \n",
        "model = Sequential()\n",
        "\n",
        "# Add Embedding layer\n",
        "model.add(Embedding(vocab_size, 50 ,input_length=max_pad,weights=[trained_embedding_matrix],trainable=True))\n",
        "\n",
        "model.add(Bidirectional(LSTM(256,return_sequences=True)))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(TimeDistributed(Dense(40, activation=\"relu\")))\n",
        "# Add timeDistributed Layer\n",
        "model.add(TimeDistributed(Dense(len(label_dict.keys()), activation=\"softmax\")))\n",
        "\n",
        "# Compile model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()\n",
        "#https://towardsdatascience.com/named-entity-recognition-ner-using-keras-bidirectional-lstm-28cd3f301f54"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oJxq8CTAmJhf",
        "outputId": "507c3855-ec6c-4fab-de29-df60fdf1aa74"
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_31\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_31 (Embedding)    (None, 124, 50)           1050500   \n",
            "                                                                 \n",
            " bidirectional_11 (Bidirecti  (None, 124, 512)         628736    \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dropout_27 (Dropout)        (None, 124, 512)          0         \n",
            "                                                                 \n",
            " time_distributed_54 (TimeDi  (None, 124, 40)          20520     \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            " time_distributed_55 (TimeDi  (None, 124, 9)           369       \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,700,125\n",
            "Trainable params: 1,700,125\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "model.fit(train_tokens2, train_labels_int_onehot, epochs=5, verbose=1,validation_data=(val_tokens2, val_labels_int_onehot))\n",
        "# evaluate the model\n",
        "\n",
        "y_pred = model.predict(test_tokens2, verbose=1)\n",
        "pred,true_labels=int_to_label(y_pred,test_labels_int_onehot)##convert integers back to labels\n",
        "preds=remove_padding(pred)### remove padding \n",
        "\n",
        "from seqeval.metrics import classification_report\n",
        "print(classification_report(test_labels, preds))\n",
        "\n",
        "###https://github.com/Akshayc1/named-entity-recognition/blob/master/NER%20using%20Bidirectional%20LSTM%20-%20CRF%20.ipynb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dRUiw-R5masQ",
        "outputId": "a59546b8-2c72-4404-fee7-c87726c76d5f"
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "439/439 [==============================] - 12s 21ms/step - loss: 0.0921 - accuracy: 0.9814 - val_loss: 0.1062 - val_accuracy: 0.9814\n",
            "Epoch 2/5\n",
            "439/439 [==============================] - 8s 19ms/step - loss: 0.0311 - accuracy: 0.9905 - val_loss: 0.1311 - val_accuracy: 0.9834\n",
            "Epoch 3/5\n",
            "439/439 [==============================] - 9s 20ms/step - loss: 0.0175 - accuracy: 0.9949 - val_loss: 0.1407 - val_accuracy: 0.9848\n",
            "Epoch 4/5\n",
            "439/439 [==============================] - 9s 20ms/step - loss: 0.0103 - accuracy: 0.9972 - val_loss: 0.1446 - val_accuracy: 0.9852\n",
            "Epoch 5/5\n",
            "439/439 [==============================] - 9s 20ms/step - loss: 0.0070 - accuracy: 0.9980 - val_loss: 0.1470 - val_accuracy: 0.9854\n",
            "108/108 [==============================] - 1s 7ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         LOC       0.41      0.42      0.41      1668\n",
            "        MISC       0.43      0.42      0.43       702\n",
            "         ORG       0.59      0.42      0.49      1661\n",
            "         PER       0.30      0.17      0.22      1617\n",
            "\n",
            "   micro avg       0.44      0.35      0.39      5648\n",
            "   macro avg       0.43      0.36      0.39      5648\n",
            "weighted avg       0.43      0.35      0.38      5648\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Best Model Trained with Train + Val"
      ],
      "metadata": {
        "id": "lsCUGT_D3RBL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_tokens2_temp=train_tokens2.copy()\n",
        "val_tokens2_temp=val_tokens2.copy()\n",
        "\n",
        "train_labels_int_onehot_temp=train_labels_int_onehot.copy()\n",
        "val_labels_int_onehot_temp=val_labels_int_onehot.copy()\n",
        "\n",
        "train_and_val_tokens=np.concatenate((train_tokens2_temp, val_tokens2_temp), axis=0)\n",
        "\n",
        "train_and_val_labels=np.concatenate((train_labels_int_onehot_temp, val_labels_int_onehot_temp), axis=0)"
      ],
      "metadata": {
        "id": "5VMpIvEU3hIn"
      },
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##dense  20->40, BILSTM 256 \n",
        "model = Sequential()\n",
        "\n",
        "# Add Embedding layer\n",
        "model.add(Embedding(vocab_size, 50 ,input_length=max_pad,weights=[pre_trained_embedding_matrix],trainable=True))\n",
        "\n",
        "model.add(Bidirectional(LSTM(512,return_sequences=True)))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(TimeDistributed(Dense(40, activation=\"relu\")))\n",
        "# Add timeDistributed Layer\n",
        "model.add(TimeDistributed(Dense(len(label_dict.keys()), activation=\"softmax\")))\n",
        "\n",
        "# Compile model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()\n",
        "#https://towardsdatascience.com/named-entity-recognition-ner-using-keras-bidirectional-lstm-28cd3f301f54"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IqZITi3Qmamg",
        "outputId": "5d034df5-9f96-4bfd-a2d2-ddee7bd0f747"
      },
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_35\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_35 (Embedding)    (None, 124, 50)           1050500   \n",
            "                                                                 \n",
            " bidirectional_15 (Bidirecti  (None, 124, 1024)        2306048   \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dropout_31 (Dropout)        (None, 124, 1024)         0         \n",
            "                                                                 \n",
            " time_distributed_62 (TimeDi  (None, 124, 40)          41000     \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            " time_distributed_63 (TimeDi  (None, 124, 9)           369       \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,397,917\n",
            "Trainable params: 3,397,917\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "model.fit(train_and_val_tokens, train_and_val_labels, epochs=20, verbose=1)\n",
        "# evaluate the model\n",
        "\n",
        "y_pred = model.predict(test_tokens2, verbose=1)\n",
        "pred,true_labels=int_to_label(y_pred,test_labels_int_onehot)##convert integers back to labels\n",
        "preds=remove_padding(pred)### remove padding \n",
        "\n",
        "from seqeval.metrics import classification_report\n",
        "print(classification_report(test_labels, preds))\n",
        "\n",
        "###https://github.com/Akshayc1/named-entity-recognition/blob/master/NER%20using%20Bidirectional%20LSTM%20-%20CRF%20.ipynb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3DX0Eq853jZf",
        "outputId": "17220239-7256-4a4c-ff74-02fdd1166e70"
      },
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "541/541 [==============================] - 22s 34ms/step - loss: 0.0692 - accuracy: 0.9850\n",
            "Epoch 2/20\n",
            "541/541 [==============================] - 18s 34ms/step - loss: 0.0280 - accuracy: 0.9928\n",
            "Epoch 3/20\n",
            "541/541 [==============================] - 19s 34ms/step - loss: 0.0210 - accuracy: 0.9946\n",
            "Epoch 4/20\n",
            "541/541 [==============================] - 19s 34ms/step - loss: 0.0170 - accuracy: 0.9956\n",
            "Epoch 5/20\n",
            "541/541 [==============================] - 19s 35ms/step - loss: 0.0145 - accuracy: 0.9961\n",
            "Epoch 6/20\n",
            "541/541 [==============================] - 19s 35ms/step - loss: 0.0120 - accuracy: 0.9966\n",
            "Epoch 7/20\n",
            "541/541 [==============================] - 19s 35ms/step - loss: 0.0103 - accuracy: 0.9970\n",
            "Epoch 8/20\n",
            "541/541 [==============================] - 19s 35ms/step - loss: 0.0084 - accuracy: 0.9974\n",
            "Epoch 9/20\n",
            "541/541 [==============================] - 19s 35ms/step - loss: 0.0074 - accuracy: 0.9976\n",
            "Epoch 10/20\n",
            "541/541 [==============================] - 19s 35ms/step - loss: 0.0059 - accuracy: 0.9980\n",
            "Epoch 11/20\n",
            "541/541 [==============================] - 19s 35ms/step - loss: 0.0051 - accuracy: 0.9982\n",
            "Epoch 12/20\n",
            "541/541 [==============================] - 19s 35ms/step - loss: 0.0044 - accuracy: 0.9984\n",
            "Epoch 13/20\n",
            "541/541 [==============================] - 19s 35ms/step - loss: 0.0039 - accuracy: 0.9986\n",
            "Epoch 14/20\n",
            "541/541 [==============================] - 19s 35ms/step - loss: 0.0034 - accuracy: 0.9988\n",
            "Epoch 15/20\n",
            "541/541 [==============================] - 19s 35ms/step - loss: 0.0029 - accuracy: 0.9990\n",
            "Epoch 16/20\n",
            "541/541 [==============================] - 19s 35ms/step - loss: 0.0026 - accuracy: 0.9991\n",
            "Epoch 17/20\n",
            "541/541 [==============================] - 19s 35ms/step - loss: 0.0021 - accuracy: 0.9993\n",
            "Epoch 18/20\n",
            "541/541 [==============================] - 19s 35ms/step - loss: 0.0019 - accuracy: 0.9993\n",
            "Epoch 19/20\n",
            "541/541 [==============================] - 19s 35ms/step - loss: 0.0017 - accuracy: 0.9994\n",
            "Epoch 20/20\n",
            "541/541 [==============================] - 19s 35ms/step - loss: 0.0015 - accuracy: 0.9995\n",
            "108/108 [==============================] - 2s 13ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         LOC       0.57      0.54      0.55      1668\n",
            "        MISC       0.45      0.42      0.43       702\n",
            "         ORG       0.60      0.47      0.53      1661\n",
            "         PER       0.46      0.32      0.38      1617\n",
            "\n",
            "   micro avg       0.53      0.44      0.48      5648\n",
            "   macro avg       0.52      0.44      0.47      5648\n",
            "weighted avg       0.53      0.44      0.48      5648\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FDnYCXXEUG_g"
      },
      "source": [
        "# **MY REPORT**\n",
        "\n",
        "## **CRF** \n",
        "First I started by reading the data,read it line by line and extracting the word, pos tag, chunk tag and the ner tag. I keep each sentence as different arrays in a big array. I also eliminate the docstart lines since we dont need them. Use this function for creating train val and test data. Later I create the gazetteer using the wikipedia pages. According to my knowledge we need to extract all the href link titles since all of them are kind of a special entity.  I observed that href titles are located between the special charcters of \"&gt ; and /a&gt therefore I created a regex to extract the href strings then added them all to a list one by one. \n",
        "\n",
        "CRF Features:\n",
        "\n",
        "I used https://eli5.readthedocs.io/en/latest/tutorials/sklearn_crfsuite.html to extract the crf features. For neighbor features I added 2 if cases to check the previous and next word existance and edit the neighbor features accordingly. I also defined functions to extract word shape, and used word shape function to create short word shape. I applied token2features to all sentences in the dataset as well as created label lists for train val and test data.\n",
        "\n",
        "After having the sentences and labels data ready,  I performed Grid search for CRF I, best parameters were {'algorithm': 'lbfgs', 'all_possible_transitions': True, 'max_iterations': 100} \n",
        "By using them I predict the test data and obtained 0.82 macro F1 score.\n",
        "\n",
        "\n",
        "Later I trained different crf models with adding each features one by one cumulatively.  I did this by taking sub-sample of feature dictionary   every time for new features. Every time I predict the validation dataset and saved each metric for later visualization. To visualize the affect of each feature on the dataset I created a dataframe with my saved arrays.\n",
        "\n",
        "###Analysis:\n",
        "\n",
        "As expected the best resulting feature sample is the one that contains every feature. When testing on test data using all the features I obtained 0.81 macro F1 and 0.96 accuracy score. The F1 score starts with 0.60 by just using stem as a feature, the greatest jump in f1 score is done by the pos_tag it increases the score by 0.13 but we cannot observe other features that has this much affect they generally increase the score by 0.03 etc. The seocnd most affcetive feature was adding the nieghbour to feature set.\n",
        "\n",
        "## **RNN**\n",
        "\n",
        "I trained in total 24 models, grouped them in 3 ; Random embedding, pre-trained embedding and trained from scratch embedding. All models are trained for 5 epochs.\n",
        "\n",
        "RANDOM:\n",
        "\n",
        "- I tried Simple RNN layer with 128 and Dense layer as 20 at initial. It gave me -\n",
        "\n",
        "- Simple Rnn with 128 units and dense layer with 40 \n",
        "\n",
        "- Simple Rnn with 256 units and dense layer with 20 \n",
        "\n",
        "- Simple Rnn with 256 units and dense layer with 40 \n",
        "\n",
        "- BiLstm with 128 and dense 20\n",
        "- BiLstm with 128 and dense 40\n",
        "- BiLstm with 256 and dense 20\n",
        "- BiLstm with 256 and dense 40\n",
        "\n",
        "Changing Simple RNN parameters did not affect the model much, the macro f1 generally resulted in 0.36 and it took longer time to train than Lstm layer.\n",
        "I observed that even though the train loss became quickly less the validation loss started increasing at every epoch this showed overfitting therefore I also added dropout layer with 0.5 probability to overcomet this however it did not change the results much.\n",
        "\n",
        "PRETRAINED EMBEDDING:\n",
        "\n",
        "The above combinations are also trained but this time with an embedding layer from gensim api. I choose glpve twitter data and embedding size of 50.\n",
        "As expected pre-trained model performed slightly better than random embeddings I observed the highest 0.4  macro F1 with BIlstm layers on test set.\n",
        "\n",
        "\n",
        "TRAINED EMBEDDING: \n",
        "\n",
        "The above combinations are also trained but this time with an embedding layer trained from scratch with our own train dataset using Word2Vec again I choose size as 50. Trained embedding matrix did not performed as well as pre-trained it is similar to random embedding Simple Rnn fluctuates around 0.36 and Bilstm around 0.39\n",
        "\n",
        "\n",
        "I also tried using LSTM layer which is not bidirectional like bilstm but it did not perform as good as bilstm therefore I did not include it in models. Finally I trained the best performed model with using both train and validation data as train data, when I trained it for longer epochs like 10 and 20 I observed better Macro F1 scores, the highest achieved is 0.47 with 512 bilstm layer and 20 epochs. Abover combinations would probably perform a little bit better if they were trained for longer.\n",
        "\n",
        "All in all, I obtained way better results when using CRF however it is computaitonally more expensive and time consuming to extract all the features.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "jupyter nbconvert --to html /content/Project_2_Notebook.ipynb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VK6-pJi693LR",
        "outputId": "fc236990-125c-4400-fb9e-c0c746a5a770"
      },
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NbConvertApp] Converting notebook /content/Project_2_Notebook.ipynb to html\n",
            "/usr/local/lib/python3.7/dist-packages/nbconvert/filters/datatypefilter.py:41: UserWarning: Your element with mimetype(s) dict_keys(['application/vnd.colab-display-data+json']) is not able to be represented.\n",
            "  mimetypes=output.keys())\n",
            "[NbConvertApp] Writing 639668 bytes to /content/Project_2_Notebook.html\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {},
          "execution_count": 146
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "lQseqv3V-IA6"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": " Project_2 Notebook.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}